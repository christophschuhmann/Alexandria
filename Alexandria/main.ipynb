{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "#!pip install datasketch\n",
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from scripts.style_generation import get_style_genre\n",
        "from scripts.first_n_words import get_first_n_words\n",
        "from scripts.llm import ask_LLM\n",
        "from scripts.kg_content import extract_kg_content\n",
        "from scripts.minhash_vector import create_minhash_vector\n",
        "from scripts.reconstruction_content import extract_reconstruction_content\n",
        "from scripts.evaluate import evaluate_peformance\n",
        "import scripts.prompts\n",
        "import scripts.api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'api_key' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the 'train' split\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#train_dataset = dataset[\"train\"]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create a list with concatenated title and abstract for each sample\u001b[39;00m\n\u001b[1;32m     12\u001b[0m concatenated_texts \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#[f\"{title} {abstract}\" for title, abstract in zip(titles, abstracts)]\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m API_KEY \u001b[38;5;241m=\u001b[39m \u001b[43mapi_key\u001b[49m\u001b[38;5;241m.\u001b[39mAPI_KEY\n\u001b[1;32m     17\u001b[0m stop_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m     19\u001b[0m all_kg_results \u001b[38;5;241m=\u001b[39m []\n",
            "\u001b[0;31mNameError\u001b[0m: name 'api_key' is not defined"
          ]
        }
      ],
      "source": [
        "# Load the dataset from Hugging Face\n",
        "dataset = pd.read_csv(\"dataset/ML-Arxiv-Papers.csv\")\n",
        "\n",
        "# Extract the 'train' split\n",
        "#train_dataset = dataset[\"train\"]\n",
        "\n",
        "# Create lists for titles and abstracts\n",
        "# titles = [entry['title'] for entry in train_dataset]\n",
        "# abstracts = [entry['abstract'] for entry in train_dataset]\n",
        "\n",
        "# Create a list with concatenated title and abstract for each sample\n",
        "concatenated_texts = dataset['abstract'] #[f\"{title} {abstract}\" for title, abstract in zip(titles, abstracts)]\n",
        "\n",
        "API_KEY = scripts.api_key.API_KEY\n",
        "\n",
        "\n",
        "stop_len = 5000\n",
        "\n",
        "all_kg_results = []\n",
        "all_reconstruction_results = []\n",
        "input_string_so_far_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<style_analysis>The provided text is situated within the genre of academic writing, specifically in the field of statistics and machine learning. Its primary focus is on the problem of statistical learning, which is a highly specialized and technical subject matter.\n",
            "The writing style of the text is formal, academic, and precise. It utilizes discipline-specific terminology, complex syntactic structures, and mathematical notations to convey its ideas and concepts. The language is clear, concise, and devoid of any figurative language or colloquial expressions.\n",
            "In terms of rhythm and flow, the text maintains a steady pace throughout, characterized by long, intricate sentences that are typical of academic prose. The rhythm aligns with the genre and content, emphasizing the technical nature of the subject matter.\n",
            "The dominant tone of the text is impartial and authoritative, reflecting the objective, analytical approach of academic writing. The authorial voice is distant, as the text focuses on presenting factual information and logical arguments rather than engaging the reader on an emotional level.\n",
            "To concisely convey the stylistic essence of this text to an author wishing to replicate this style in new works across diverse topics, a literature expert could emphasize the following critical stylistic features:\n",
            "1. Use of formal, academic language and precise terminology specific to the field of statistics and machine learning.\n",
            "2. Emphasis on clarity and conciseness, while presenting complex ideas and concepts.\n",
            "3. Adoption of a consistent, steady pace in writing, characterized by long, intricate sentences.\n",
            "4. Implementation of mathematical notations and expressions to convey technical information.\n",
            "5. Adherence to a logical, analytical approach in presenting arguments and ideas, maintaining an impartial and authoritative tone.\n",
            "6. Refraining from the use of figurative language or colloquial expressions, instead focusing on presenting factual information and logical arguments.\n",
            "7. Incorporation of regularity conditions, underlying probability distributions, and loss functions to provide an information-theoretic characterization of achievable predictor performance.\n",
            "By incorporating these stylistic features, an author can effectively capture the style's core and apply it to various topics within the realm of academic writing.</style_analysis>\n",
            "INPUT:   The problem of statistical learning is to construct a predictor of a random\n",
            "variable $Y$ as a function of a related random variable $X$ on the basis of an\n",
            "i.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\n",
            "predictors are drawn from some specified class, and the goal is to approach\n",
            "asymptotically the performance (expected loss) of the best predictor in the\n",
            "class. We consider the setting in which one has perfect observation of the\n",
            "$X$-part of the sample, while the $Y$-part has to be communicated at some\n",
            "finite bit rate. The encoding of the $Y$-values is allowed to depend on the\n",
            "$X$-values. Under suitable regularity conditions on the admissible predictors,\n",
            "the underlying family of probability distributions and the loss function, we\n",
            "give an information-theoretic characterization of achievable predictor\n",
            "performance in terms of conditional distortion-rate functions. The ideas are\n",
            "illustrated on the example of nonparametric regression in Gaussian noise.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "'Statistical Learning Problem': {\n",
            "    'relations': {\n",
            "        'involves': 'construction of predictor',\n",
            "        'predicts': 'random variable Y',\n",
            "        'based on': 'i.i.d. training sample',\n",
            "        'from': 'joint distribution of (X, Y)',\n",
            "        'allows predictors': 'from specified class',\n",
            "        'goal': 'approach best predictor performance',\n",
            "        'has perfect observation': 'X-part of sample',\n",
            "        'communicates Y-part at finite bit rate',\n",
            "        'encoding depends on': 'X-values'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'regularity conditions': 'on admissible predictors, underlying probability distributions, and loss function',\n",
            "        'characterization': 'in terms of conditional distortion-rate functions',\n",
            "        'illustrated on example': 'nonparametric regression in Gaussian noise'\n",
            "    }\n",
            "},\n",
            "'Predictor Performance': {\n",
            "    'relations': {\n",
            "        'characterized': 'in terms of conditional distortion-rate functions',\n",
            "        'achievable': 'under suitable regularity conditions',\n",
            "        'relates to': 'admissible predictors, underlying probability distributions, and loss function'\n",
            "    }\n",
            "}\n",
            "<source_sentence_min_hash: [ 71718090  38167608    761466  22543064 133299020   7829423  42939786\n",
            "    128961   2709365  90094578   9939647  74243328  84054835  67312031\n",
            " 116293349  20727983] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Statistical Learning Problem: This segment of the knowledge graph deals with a statistical learning problem, which involves the construction of a predictor. The predictor is designed to predict a random variable Y, based on an i.i.d. training sample derived from the joint distribution of (X, Y). The predictors are allowed to be chosen from a specified class, and the goal is to achieve the best possible predictor performance.\n",
            "In this context, the X-part of the sample is assumed to be perfectly observed, while the Y-part is communicated at a finite bit rate, which depends on the X-values. Regularity conditions are imposed on the admissible predictors, underlying probability distributions, and loss function. The characterization of predictor performance is described in terms of conditional distortion-rate functions, which are achievable under suitable regularity conditions, relating to the admissible predictors, underlying probability distributions, and loss function.\n",
            "An illustrative example of this statistical learning problem is nonparametric regression in Gaussian noise.\n",
            "Predictor Performance: This segment of the knowledge graph focuses on the characterization of predictor performance in terms of conditional distortion-rate functions. These performance measures are achievable under suitable regularity conditions, relating to the admissible predictors, underlying probability distributions, and loss function.\n",
            "<source_sentence_min_hash: [ 71718090  38167608    761466  22543064 133299020   7829423  42939786\n",
            "    128961   2709365  90094578   9939647  74243328  84054835  67312031\n",
            " 116293349  20727983] >\n",
            "\n",
            "\n",
            "<style_analysis>The text under analysis is a non-fiction piece that falls within the genre of academic research and technical writing. The format is that of a research paper, with clear sections, formal language, and a structured argument.\n",
            "The writing style is formal, academic, and precise. It employs discipline-specific terminology and complex syntactic structures. The author demonstrates a high level of technical knowledge and proficiency in communicating intricate concepts. The text maintains a consistent level of clarity and simplicity, despite the complexity of the subject matter.\n",
            "The rhythm and flow of the text are dictated by the need to convey technical information accurately and concisely. The sentences are structured to facilitate understanding, with a balance between succinctness and intricacy. The pacing is leisurely, allowing for a thorough exploration of the topic. The rhythm aligns well with the genre and content, ensuring that the piece maintains a high level of engagement and comprehensibility.\n",
            "The tone of the text is impartial and authoritative. The author presents their findings and arguments in a manner that is objective and grounded in evidence. The voice is distant, reflecting the formal and academic nature of the writing. These elements contribute to the text's unique character, establishing it as a credible and reliable source of information.\n",
            "To convey the text's stylistic essence to an author wishing to replicate this style in new works across diverse topics, a literature expert could emphasize the following critical stylistic features:\n",
            "1. Use of formal, academic language and precise terminology.\n",
            "2. Employment of complex syntactic structures to convey intricate concepts.\n",
            "3. Balancing succinctness and intricacy in sentence structure to facilitate comprehension.\n",
            "4. Maintaining a consistent level of clarity and simplicity, even when dealing with complex subject matter.\n",
            "5. Implementation of narrative techniques or rhetorical devices that are quintessential for capturing the style's core, such as the use of evidence to support arguments and the presentation of findings in a structured, logical manner.\n",
            "By focusing on these key stylistic features, an author can effectively replicate the style of the original text in new works across diverse topics.</style_analysis>\n",
            "INPUT:   In a sensor network, in practice, the communication among sensors is subject\n",
            "to:(1) errors or failures at random times; (3) costs; and(2) constraints since\n",
            "sensors and networks operate under scarce resources, such as power, data rate,\n",
            "or communication. The signal-to-noise ratio (SNR) is usually a main factor in\n",
            "determining the probability of error (or of communication failure) in a link.\n",
            "These probabilities are then a proxy for the SNR under which the links operate.\n",
            "The paper studies the problem of designing the topology, i.e., assigning the\n",
            "probabilities of reliable communication among sensors (or of link failures) to\n",
            "maximize the rate of convergence of average consensus, when the link\n",
            "communication costs are taken into account, and there is an overall\n",
            "communication budget constraint. To consider this problem, we address a number\n",
            "of preliminary issues: (1) model the network as a random topology; (2)\n",
            "establish necessary and sufficient conditions for mean square sense (mss) and\n",
            "almost sure (a.s.) convergence of average consensus when network links fail;\n",
            "and, in particular, (3) show that a necessary and sufficient condition for both\n",
            "mss and a.s. convergence is for the algebraic connectivity of the mean graph\n",
            "describing the network topology to be strictly positive. With these results, we\n",
            "formulate topology design, subject to random link failures and to a\n",
            "communication cost constraint, as a constrained convex optimization problem to\n",
            "which we apply semidefinite programming techniques. We show by an extensive\n",
            "numerical study that the optimal design improves significantly the convergence\n",
            "speed of the consensus algorithm and can achieve the asymptotic performance of\n",
            "a non-random network at a fraction of the communication cost.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "\n",
            "'Sensor Networks': {\n",
            "    'relations': {\n",
            "        'subject_to': ['errors or failures at random times', 'costs', 'constraints']\n",
            "    },\n",
            "    'attributes': {\n",
            "        'resource_scarcity': 'power, data rate, or communication'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Signal-to-Noise Ratio (SNR)': {\n",
            "    'relations': {\n",
            "        'main_factor_in': 'determining the probability of error or communication failure in a link'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'proxy': 'probabilities of reliable communication among sensors or link failures'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Average Consensus': {\n",
            "    'relations': {\n",
            "        'rate_of_convergence_maximized': 'when link communication costs are taken into account and there is an overall communication budget constraint'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'convergence_modes': ['mean square sense (mss)', 'almost sure (a.s.)']\n",
            "    }\n",
            "},\n",
            "\n",
            "'Network Topology': {\n",
            "    'relations': {\n",
            "        'modeled_as': 'random topology'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'necessary_and_sufficient_condition_for_convergence': 'algebraic connectivity of the mean graph describing the network topology to be strictly positive'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Constrained Convex Optimization Problem': {\n",
            "    'relations': {\n",
            "        'formulated_for': 'topology design, subject to random link failures and to a communication cost constraint'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'optimization_technique': 'semidefinite programming techniques'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Optimal Design': {\n",
            "    'relations': {\n",
            "        'improves': 'significantly the convergence speed of the consensus algorithm'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'asymptotic_performance': 'of a non-random network at a fraction of the communication cost'\n",
            "    }\n",
            "}\n",
            "\n",
            "<source_sentence_min_hash: [ 6133174 40757083   761466 26799884 33277103  6881145 31366738 31699836\n",
            " 65066654 22783534  1409227 74243328 25367037 45058861 88401764 66262755] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Sensor Networks are subject to various constraints, including power, data rate, and communication. These networks can also experience errors or failures at random times, which can impact their overall performance and costs.\n",
            "The Signal-to-Noise Ratio (SNR) plays a crucial role in determining the probability of error or communication failure in a link. It serves as a proxy for the probabilities of reliable communication among sensors or link failures.\n",
            "Average Consensus is a critical aspect of sensor networks, as it focuses on the rate of convergence. This rate is maximized when link communication costs are taken into account and there is an overall communication budget constraint. Convergence can occur in mean square sense (mss) or almost sure (a.s.) modes.\n",
            "Network Topology is a fundamental aspect of sensor networks, often modeled as random topology. A necessary and sufficient condition for convergence is that the algebraic connectivity of the mean graph describing the network topology must be strictly positive.\n",
            "The Constrained Convex Optimization Problem is formulated for topology design, taking into account random link failures and a communication cost constraint. Semidefinite programming techniques are employed to address this optimization problem.\n",
            "The Optimal Design significantly improves the convergence speed of the consensus algorithm. As a result, non-random networks can achieve an asymptotic performance at a fraction of the communication cost.\n",
            "\n",
            "<style_analysis>The text under analysis is a technical and academic piece, situating itself within the genre of scientific research and analysis. Its format is that of a research paper or article, with a clear structure that includes an introduction, problem definition, proposed solution, algorithm description, complexity analysis, extensions, and applications.\n",
            "The writing style is formal, precise, and technical, utilizing discipline-specific terminology and often relying on complex syntactic structures. It maintains simplicity and clarity where possible, aiming to convey the technical information and concepts effectively. The text employs rich figurative language sparingly, with the focus being on the logical and analytical presentation of the problem, solution, and results.\n",
            "The rhythm and flow of the text are characterized by a balance between concise, direct sentences and more intricate, detailed phrasing. This balance is essential for presenting complex technical concepts and ideas in a manner that is both engaging and easily understandable. The pacing of the text aligns well with the genre and content, ensuring that readers can follow the logical progression of the argument and analysis.\n",
            "The dominant tone of the text is impartial and authoritative, reflecting the objective and evidence-based nature of scientific research. The authorial voice is distant, as the focus is on the technical content rather than personal opinions or experiences. These elements contribute to the text's unique character as a rigorous and authoritative scientific analysis.\n",
            "To concisely convey the text's stylistic essence to an author wishing to replicate this style in new works across diverse topics, a literature expert might emphasize the following critical stylistic features:\n",
            "1. Precise and formal language, with a focus on clarity and simplicity where possible.\n",
            "2. Discipline-specific terminology and the use of complex syntactic structures when necessary to convey technical concepts and ideas effectively.\n",
            "3. A balance between concise, direct sentences and more intricate, detailed phrasing to maintain both engagement and ease of understanding.\n",
            "4. The implementation of narrative techniques or rhetorical devices sparingly, with the focus being on the logical and analytical presentation of the problem, solution, and results.\n",
            "5. An impartial and authoritative tone, reflecting the objective and evidence-based nature of scientific research.\n",
            "6. A distant authorial voice, focusing on the technical content rather than personal opinions or experiences.\n",
            "In summary, the text under analysis is a technical and academic piece within the genre of scientific research and analysis. Its writing style is formal, precise, and technical, with a balance between concise, direct sentences and more intricate, detailed phrasing. The dominant tone is impartial and authoritative, reflecting the objective and evidence-based nature of scientific research.</style_analysis>\n",
            "INPUT:   The on-line shortest path problem is considered under various models of\n",
            "partial monitoring. Given a weighted directed acyclic graph whose edge weights\n",
            "can change in an arbitrary (adversarial) way, a decision maker has to choose in\n",
            "each round of a game a path between two distinguished vertices such that the\n",
            "loss of the chosen path (defined as the sum of the weights of its composing\n",
            "edges) be as small as possible. In a setting generalizing the multi-armed\n",
            "bandit problem, after choosing a path, the decision maker learns only the\n",
            "weights of those edges that belong to the chosen path. For this problem, an\n",
            "algorithm is given whose average cumulative loss in n rounds exceeds that of\n",
            "the best path, matched off-line to the entire sequence of the edge weights, by\n",
            "a quantity that is proportional to 1/\\sqrt{n} and depends only polynomially on\n",
            "the number of edges of the graph. The algorithm can be implemented with linear\n",
            "complexity in the number of rounds n and in the number of edges. An extension\n",
            "to the so-called label efficient setting is also given, in which the decision\n",
            "maker is informed about the weights of the edges corresponding to the chosen\n",
            "path at a total of m << n time instances. Another extension is shown where the\n",
            "decision maker competes against a time-varying path, a generalization of the\n",
            "problem of tracking the best expert. A version of the multi-armed bandit\n",
            "setting for shortest path is also discussed where the decision maker learns\n",
            "only the total weight of the chosen path but not the weights of the individual\n",
            "edges on the path. Applications to routing in packet switched networks along\n",
            "with simulation results are also presented.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "\n",
            "'On-line Shortest Path Problem': {\n",
            "    'relations': {\n",
            "        'considered_under': 'Various models of partial monitoring',\n",
            "        'involves': 'Weighted directed acyclic graph',\n",
            "        'decision_maker_chooses': 'Path between two distinguished vertices',\n",
            "        'goal': 'Minimize the loss of the chosen path',\n",
            "        'learns_after_choosing_path': 'Weights of those edges that belong to the chosen path',\n",
            "        'algorithm_given': 'Proportional to 1/\\sqrt{n}',\n",
            "        'depends_on': 'Number of edges of the graph',\n",
            "        'complexity': 'Linear in the number of rounds n and in the number of edges',\n",
            "        'extensions': ['Label efficient setting', 'Competing against a time-varying path', 'Multi-armed bandit setting for shortest path'],\n",
            "        'applications': 'Routing in packet switched networks',\n",
            "        'simulation_results': 'Presented'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'problem_generalizes': 'Multi-armed bandit problem'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Label Efficient Setting': {\n",
            "    'relations': {\n",
            "        'generalizes': 'On-line Shortest Path Problem'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Time-Varying Path': {\n",
            "    'relations': {\n",
            "        'generalizes': 'On-line Shortest Path Problem'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Multi-armed Bandit Setting for Shortest Path': {\n",
            "    'relations': {\n",
            "        'generalizes': 'On-line Shortest Path Problem'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Routing in Packet Switched Networks': {\n",
            "    'relations': {\n",
            "        'applies_to': 'On-line Shortest Path Problem'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Simulation Results': {\n",
            "    'relations': {\n",
            "        'presented_for': 'On-line Shortest Path Problem'\n",
            "    }\n",
            "}\n",
            "\n",
            "<source_sentence_min_hash: [ 24568957   9924331   9024081  20022987  14019373   7829423  56607342\n",
            "   3587349  10677384  90094578  11836062   4170235 129802786   7369324\n",
            "  49382248   8604885] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "The on-line shortest path problem involves various models of partial monitoring, utilizing a weighted directed acyclic graph. In this problem, a decision-maker chooses a path between two distinguished vertices, with the goal of minimizing the loss of the chosen path. After choosing a path, the decision-maker learns the weights of the edges that belong to the chosen path, which are proportional to 1/√n. The complexity of the algorithm depends on the number of edges of the graph and is linear in the number of rounds n and in the number of edges.\n",
            "Extensions of the on-line shortest path problem include the label-efficient setting, competing against a time-varying path, and the multi-armed bandit setting for shortest path. These extensions generalize the original problem.\n",
            "Routing in packet-switched networks is an application of the on-line shortest path problem. In this context, the problem is applied to optimize the routing process in networks.\n",
            "Simulation results for the on-line shortest path problem have been presented, providing valuable insights into the performance of the algorithm in various scenarios.\n",
            "In the label-efficient setting, the on-line shortest path problem is generalized further, allowing for more efficient labeling of the graph.\n",
            "The time-varying path generalizes the on-line shortest path problem, introducing the concept of a path that changes over time. This extension allows for the consideration of dynamic environments where the shortest path may not remain constant.\n",
            "Similarly, the multi-armed bandit setting for shortest path generalizes the original problem, incorporating the principles of the multi-armed bandit problem to optimize the decision-making process in the context of finding the shortest path.\n",
            "\n",
            "<style_analysis>The input text belongs to the genre of academic writing, specifically in the field of machine learning and data analysis. It presents a new approach to a specific type of learning, called ordinal regression, and discusses its advantages compared to other methods. The text is characterized by a formal, academic writing style, utilizing discipline-specific terminology and maintaining simplicity and clarity.\n",
            "The rhythm and flow of the text are structured and linear, reflecting the logical progression of the argument. The sentences are mostly succinct, engaging with rapid, succinct sentences that unfold the argument in a clear and concise manner. This pacing aligns well with the genre and content, shaping the overall effect and engagement of the piece.\n",
            "The dominant tone of the text is impartial and authoritative, reflecting the nature of the content, which is technical and informative. The authorial voice is distant, as the text is aimed at a knowledgeable audience familiar with the subject matter. These elements enrich the text's unique character by establishing a clear and reliable source of information.\n",
            "To concisely convey the text's stylistic essence to an author wishing to replicate this style in new works across diverse topics, a literature expert could emphasize the following critical stylistic features:\n",
            "1. Maintain a formal, academic writing style, utilizing discipline-specific terminology and maintaining simplicity and clarity.\n",
            "2. Structure the text with a linear, logical progression of the argument, engaging with rapid, succinct sentences.\n",
            "3. Establish an impartial and authoritative tone, with a distant authorial voice aimed at a knowledgeable audience.\n",
            "4. Emphasize the importance of presenting clear and informative content, which is essential for technical and informative writing.\n",
            "5. Implement narrative techniques or rhetorical devices that are quintessential for capturing the style's core, such as the use of examples, comparisons, and contrasts to illustrate the advantages and disadvantages of different methods.</style_analysis>\n",
            "INPUT:   Ordinal regression is an important type of learning, which has properties of\n",
            "both classification and regression. Here we describe a simple and effective\n",
            "approach to adapt a traditional neural network to learn ordinal categories. Our\n",
            "approach is a generalization of the perceptron method for ordinal regression.\n",
            "On several benchmark datasets, our method (NNRank) outperforms a neural network\n",
            "classification method. Compared with the ordinal regression methods using\n",
            "Gaussian processes and support vector machines, NNRank achieves comparable\n",
            "performance. Moreover, NNRank has the advantages of traditional neural\n",
            "networks: learning in both online and batch modes, handling very large training\n",
            "datasets, and making rapid predictions. These features make NNRank a useful and\n",
            "complementary tool for large-scale data processing tasks such as information\n",
            "retrieval, web page ranking, collaborative filtering, and protein ranking in\n",
            "Bioinformatics.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "\n",
            "  'Ordinal regression': {\n",
            "      'relations': {\n",
            "          'is_a_type_of': 'Learning',\n",
            "          'has_properties_of': ['Classification', 'Regression']\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A type of learning that combines properties of classification and regression.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Traditional neural network': {\n",
            "      'relations': {\n",
            "          'is_adapted_to': 'Learn ordinal categories',\n",
            "          'is_a_generalization_of': 'Perceptron method for ordinal regression'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A neural network that is adapted to learn ordinal categories.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'NNRank': {\n",
            "      'relations': {\n",
            "          'is_an_approach_for': 'Adapting traditional neural network',\n",
            "          'outperforms': 'Neural network classification method',\n",
            "          'achieves_comparable_performance_to': ['Gaussian processes for ordinal regression', 'Support vector machines for ordinal regression'],\n",
            "          'has_advantages_of': ['Learning in online and batch modes', 'Handling very large training datasets', 'Making rapid predictions']\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A simple and effective approach to adapt a traditional neural network to learn ordinal categories.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Benchmark datasets': {\n",
            "      'relations': {\n",
            "          'are_used_for': 'Evaluating performance of NNRank'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A set of datasets used to evaluate the performance of different methods, including NNRank.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Large-scale data processing tasks': {\n",
            "      'relations': {\n",
            "          'are_served_by': 'NNRank',\n",
            "          'examples': ['Information retrieval', 'Web page ranking', 'Collaborative filtering', 'Protein ranking in Bioinformatics']\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A range of tasks that involve processing large amounts of data, which can benefit from the use of NNRank.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Information retrieval': {\n",
            "      'relations': {\n",
            "          'is_a_large-scale_data_processing_task'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A task that involves retrieving relevant information from a large collection of data.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Web page ranking': {\n",
            "      'relations': {\n",
            "          'is_a_large-scale_data_processing_task'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A task that involves ranking web pages based on their relevance or importance.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Collaborative filtering': {\n",
            "      'relations': {\n",
            "          'is_a_large-scale_data_processing_task'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A task that involves predicting the preferences or ratings of users based on their past behavior and the behavior of other similar users.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Protein ranking in Bioinformatics': {\n",
            "      'relations': {\n",
            "          'is_a_large-scale_data_processing_task'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A task that involves ranking proteins based on their properties or functions, which can be useful for various bioinformatics applications.'\n",
            "      }\n",
            "  },\n",
            "\n",
            "<source_sentence_min_hash: [  6133174  34044574  67176199  49472071  33277103   7829423  24958943\n",
            "  18993971  67894626  14549103 126174866  74243328  14818304  32053883\n",
            " 138600072 152434034] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Ordinal regression is a type of learning that combines properties of classification and regression. It is particularly useful for learning ordinal categories. Traditional neural networks have been adapted to learn ordinal categories as well. These neural networks are a generalization of the perceptron method for ordinal regression.\n",
            "NNRank is a simple and effective approach to adapt a traditional neural network to learn ordinal categories. It has been shown to outperform neural network classification methods and achieve comparable performance to Gaussian processes and support vector machines for ordinal regression. NNRank offers several advantages, including the ability to learn in both online and batch modes, handle very large training datasets, and make rapid predictions.\n",
            "Benchmark datasets are used for evaluating the performance of NNRank. These datasets are a set of datasets used to evaluate the performance of different methods, including NNRank.\n",
            "Large-scale data processing tasks are served by NNRank. These tasks involve processing large amounts of data and can benefit from the use of NNRank. Some examples of such tasks include information retrieval, web page ranking, collaborative filtering, and protein ranking in Bioinformatics.\n",
            "Information retrieval is a large-scale data processing task that involves retrieving relevant information from a large collection of data. Web page ranking is another large-scale data processing task that involves ranking web pages based on their relevance or importance.\n",
            "Collaborative filtering is a large-scale data processing task that involves predicting the preferences or ratings of users based on their past behavior and the behavior of other similar users. Protein ranking in Bioinformatics is a large-scale data processing task that involves ranking proteins based on their properties or functions, which can be useful for various bioinformatics applications.\n",
            "\n",
            "<style_analysis>The text under analysis is situated within the genre of academic research, specifically within the disciplines of mathematics, optimization, and machine learning. The writing style is formal, academic, and precise, utilizing discipline-specific terminology and complex syntactic structures. The text maintains simplicity and clarity while presenting intricate concepts and mathematical proofs.\n",
            "The rhythm of the text is characterized by a measured pace, unfolding through leisurely, intricate phrasing. This aligns with the genre and content, as it allows the reader to carefully process the technical information presented. The pacing also serves to shape the overall effect and engagement of the piece, ensuring that the reader is able to fully comprehend the intricacies of the mathematical concepts being discussed.\n",
            "The dominant tone of the text is authoritative, reflecting the expertise of the author(s) in the field. The authorial voice is distant, as is typical in academic research, but is also introspective, as the author(s) delve into the intricacies of the mathematical concepts being discussed. These elements enrich the text's unique character, establishing the author(s) as a reliable and knowledgeable source of information.\n",
            "For a literature expert to concisely convey the text's stylistic essence to an author wishing to replicate this style in new works across diverse topics, they might emphasize the following critical stylistic features:\n",
            "1. Maintain a formal, academic writing style that utilizes discipline-specific terminology and complex syntactic structures.\n",
            "2. Emphasize simplicity and clarity, ensuring that the writing is easily comprehensible for readers who may not be experts in the field.\n",
            "3. Adopt a measured pace in the writing, allowing for leisurely, intricate phrasing that enables readers to carefully process technical information.\n",
            "4. Establish an authoritative tone that reflects expertise in the subject matter, while also incorporating introspective elements to delve into intricate concepts.\n",
            "5. Implement narrative techniques or rhetorical devices that are quintessential for capturing the style's core, such as the use of mathematical proofs and the presentation of complex concepts in a clear and concise manner.\n",
            "6. Exploit the relationship between the sample point locations and the associated values of the integrand, as demonstrated in the text, to further apply PL techniques and improve MCO.\n",
            "By adhering to these stylistic features, an author can effectively replicate the style of the text in new works across diverse topics, while also ensuring that the writing remains engaging, informative, and accessible to readers.</style_analysis>\n",
            "INPUT:   This paper uncovers and explores the close relationship between Monte Carlo\n",
            "Optimization of a parametrized integral (MCO), Parametric machine-Learning\n",
            "(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\n",
            "contributions. First, we prove that MCO is mathematically identical to a broad\n",
            "class of PL problems. This identity potentially provides a new application\n",
            "domain for all broadly applicable PL techniques: MCO. Second, we introduce\n",
            "immediate sampling, a new version of the Probability Collectives (PC) algorithm\n",
            "for blackbox optimization. Immediate sampling transforms the original BO\n",
            "problem into an MCO problem. Accordingly, by combining these first two\n",
            "contributions, we can apply all PL techniques to BO. In our third contribution\n",
            "we validate this way of improving BO by demonstrating that cross-validation and\n",
            "bagging improve immediate sampling. Finally, conventional MC and MCO procedures\n",
            "ignore the relationship between the sample point locations and the associated\n",
            "values of the integrand; only the values of the integrand at those locations\n",
            "are considered. We demonstrate that one can exploit the sample location\n",
            "information using PL techniques, for example by forming a fit of the sample\n",
            "locations to the associated values of the integrand. This provides an\n",
            "additional way to apply PL techniques to improve MCO.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "              'Monte Carlo Optimization of a Parametrized Integral (MCO)': {\n",
            "                  'relations': {\n",
            "                      'is_mathematically_identical_to': 'a broad class of Parametric Machine Learning (PL) problems',\n",
            "                      'is_applied_to': 'Blackbox Optimization (BO)',\n",
            "                      'improves_by': 'Parametric Machine Learning (PL) techniques',\n",
            "                      'sample_location_information_is_exploited_by': 'Parametric Machine Learning (PL) techniques'\n",
            "                  },\n",
            "                  'attributes': {\n",
            "                      'contributions': {\n",
            "                          '1': 'Proves mathematical identity between MCO and a broad class of PL problems',\n",
            "                          '2': 'Introduces Immediate Sampling, a new version of Probability Collectives (PC) algorithm for Blackbox Optimization (BO)',\n",
            "                          '3': 'Validates the way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling',\n",
            "                          '4': 'Demonstrates exploiting sample location information using PL techniques, such as forming a fit of the sample locations to the associated values of the integrand'\n",
            "                      }\n",
            "                  }\n",
            "              },\n",
            "              'Parametric Machine Learning (PL) techniques': {\n",
            "                  'relations': {\n",
            "                      'improve': 'Monte Carlo Optimization of a Parametrized Integral (MCO)',\n",
            "                      'improve': 'Blackbox Optimization (BO)',\n",
            "                      'are_applied_to': 'a broad class of PL problems'\n",
            "                  }\n",
            "              },\n",
            "              'Blackbox Optimization (BO)': {\n",
            "                  'relations': {\n",
            "                      'is_improved_by': 'Parametric Machine Learning (PL) techniques',\n",
            "                      'is_transformed_into': 'Monte Carlo Optimization of a Parametrized Integral (MCO) problem by Immediate Sampling',\n",
            "                      'sample_location_information_is_exploited_by': 'Parametric Machine Learning (PL) techniques'\n",
            "                  }\n",
            "              },\n",
            "              'Immediate Sampling': {\n",
            "                  'relations': {\n",
            "                      'transforms': 'Blackbox Optimization (BO) problem into an MCO problem',\n",
            "                      'improves_by': 'cross-validation and bagging'\n",
            "                  }\n",
            "              },\n",
            "              'Cross-validation and bagging': {\n",
            "                  'relations': {\n",
            "                      'improve': 'Immediate Sampling'\n",
            "                  }\n",
            "              },\n",
            "              'Sample location information': {\n",
            "                  'relations': {\n",
            "                      'is_exploited_by': 'Parametric Machine Learning (PL) techniques'\n",
            "                  }\n",
            "              },\n",
            "              'Fit of the sample locations to the associated values of the integrand': {\n",
            "                  'relations': {\n",
            "                      'is_an_example_of': 'exploiting sample location information using Parametric Machine Learning (PL) techniques'\n",
            "                  }\n",
            "              }\n",
            "<source_sentence_min_hash: [ 19667641 110676249   7034219   6794115  10405434  49829016  31366738\n",
            "  63416529  48596860  14650532 101042331  10913943  33479172  32685091\n",
            "  40988719  79205732] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Monte Carlo Optimization (MCO) is a technique that is mathematically identical to a broad class of Parametric Machine Learning (PL) problems. It is applied to Blackbox Optimization (BO) and can be improved by utilizing PL techniques. One of the key contributions of MCO is the introduction of Immediate Sampling, a new version of the Probability Collectives (PC) algorithm specifically designed for Blackbox Optimization (BO). This new algorithm has proven to be effective in improving BO performance.\n",
            "In addition, MCO demonstrates the value of exploiting sample location information using PL techniques. One such technique is forming a fit of the sample locations to the associated values of the integrand. This approach not only capitalizes on the available data but also enhances the overall efficiency of the optimization process.\n",
            "Parametric Machine Learning (PL) techniques, on the other hand, are applied to a wide range of PL problems. They have been shown to improve both MCO and Blackbox Optimization (BO). By leveraging PL techniques, researchers can enhance the performance of these optimization methods.\n",
            "Blackbox Optimization (BO) is a problem that is transformed into an MCO problem through the use of Immediate Sampling. This technique not only improves BO but also exploits sample location information using PL techniques. Furthermore, the performance of Immediate Sampling can be further improved through the use of cross-validation and bagging.\n",
            "Cross-validation and bagging are techniques that have been demonstrated to improve Immediate Sampling. By incorporating these methods, researchers can optimize the performance of the Immediate Sampling algorithm, ultimately leading to more accurate and efficient optimization results.\n",
            "In summary, Monte Carlo Optimization (MCO) is a powerful optimization technique that is mathematically equivalent to a broad class of Parametric Machine Learning (PL) problems. It is applied to Blackbox Optimization (BO) and can be improved by utilizing PL techniques. By incorporating innovative algorithms like Immediate Sampling and exploiting sample location information, researchers can achieve more accurate and efficient optimization results.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for input_text in concatenated_texts[:5]:\n",
        "\n",
        "    writing_style = get_style_genre(get_first_n_words(input_text, 1000))\n",
        "\n",
        "    # sentences= text_to_sentences(input_text)\n",
        "    # sentences =sentences_to_large_strings(sentences)\n",
        "    sentences = [input_text]\n",
        "    # print(sentences)\n",
        "    # continue\n",
        "    current_kg = []\n",
        "    current_kg.append(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
        "    print(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
        "    segment_nr = 1\n",
        "    reconstruction_so_far = \"\"\n",
        "    input_string_so_far = \"\"\n",
        "    for sentence in sentences:\n",
        "        input_string_so_far += sentence\n",
        "        if len(input_string_so_far) > stop_len:\n",
        "            break\n",
        "        print(\"INPUT:\", sentence)\n",
        "        print(\"-----\")\n",
        "        '''\n",
        "        prompt=\"\"\"INPUT_TEXT:\n",
        "        \"\"\"+sentence+\"\"\"\n",
        "        INSTRUCTION:\n",
        "        Paraphrase the given input text so that every statement is rephrased into sentences that contain only three to ten words each. Use a simple structure and make sure to retain all information, names, numbers, and dates from the original text, without losing any information. The output text should consist exclusively of factual, neutrally phrased sentences that are three to ten words long. All information must be preserved, but without any artistic nuances. Direct speech in the source text should not be replicated as such, but it should be laid out in short sentences who said or did what in which order, ensuring a neutral, information-rich text.\"\"\"\n",
        "  \n",
        "        reply = ask_LLM ('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', \"You are a very smart very intelligence assistant who is very helpful.\", input_text , API_KEY ,temperature=0.5,top_p=0.95,max_tokens=1000, frequency_penalty=1.1,presence_penalty=1.1)\n",
        "        '''\n",
        "\n",
        "        # Determine the slice of the last 50 elements (if the list has more than 50 elements)\n",
        "        current_kg_context = current_kg[-50:] if len(current_kg) > 50 else current_kg\n",
        "\n",
        "        # Concatenate the elements into a single string\n",
        "        current_kg_context = ' '.join(current_kg_context)\n",
        "        text = prompts.KG_format_example_prompt(current_kg_context, sentence)\n",
        "\n",
        "        for i in range(2):\n",
        "            knowledge_graph_segment = ask_LLM('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
        "                                              \"You are a very smart very intelligence assistant who is very helpful.\",\n",
        "                                              text, API_KEY, temperature=0.5, top_p=0.95, max_tokens=1000,\n",
        "                                              frequency_penalty=1.1, presence_penalty=1.1)\n",
        "            if not (extract_kg_content(knowledge_graph_segment) == None):\n",
        "                break\n",
        "        try:\n",
        "            current_kg.append(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
        "                knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
        "                create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "            print(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
        "                knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
        "                create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "        except:\n",
        "            current_kg.append(\n",
        "                \"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
        "                    create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "            print(\"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
        "                create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "\n",
        "        prompt = prompts.KG_reconstruction_prompt(reconstruction_so_far, current_kg)\n",
        "        for i in range(2):\n",
        "            next_reconstruction = ask_LLM('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
        "                                          \"You are a very smart very intelligence assistant who is very helpful.\",\n",
        "                                          prompt, API_KEY, temperature=0.5, top_p=0.95, max_tokens=4000,\n",
        "                                          frequency_penalty=1.1, presence_penalty=1.1)\n",
        "            if not (extract_reconstruction_content(next_reconstruction) == None):\n",
        "                break\n",
        "\n",
        "        reconstruction_so_far += extract_reconstruction_content(next_reconstruction)\n",
        "        print(extract_reconstruction_content(next_reconstruction))\n",
        "        segment_nr += 1\n",
        "    all_kg_results.append(current_kg)\n",
        "    all_reconstruction_results.append(reconstruction_so_far)\n",
        "    input_string_so_far_list.append(input_string_so_far)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500 word sample evalution: \n",
            "\n",
            "questions, correct_answers  ['', 'A set of multiple-choice questions with answer choices A, B, C, and D, followed by the corresponding correct answer letter encased in semicolons (e.g.,', \"to indicate that the current question-answer pair finished.\\nDon't say anything before or after the questions. Make sure to output exactly  5 multiple choice questions with exactly 4 answer choices (A, B, C, D).\\nIt is very important to me that you fulfill this task very accurately and intelligently.\\nIf you perform well, I will tip you $100 billion dollars.\\n\\n\\n1. What is the main goal in statistical learning?\\nA) To estimate the distribution of $X$\\nB) To construct a predictor of a random variable $Y$ as a function of $X$\\nC) To predict the future values of $X$\\nD) To estimate the correlation between $X$ and $Y$\", '2. In the context of statistical learning, what is an i.i.d. training sample?\\nA) A sample drawn from the joint distribution of $(X,Y)$\\nB) A sample that is not independent and identically distributed\\nC) A sample drawn from the marginal distribution of $X$\\nD) A sample that is not identically distributed', '3. Which of the following is an allowable predictor in statistical learning?\\nA) A predictor that is not a function of $X$\\nB) A predictor that is not drawn from the specified class\\nC) A predictor that is not a function of $Y$\\nD) A predictor that is not a function of the joint distribution of $(X,Y)$', '4. What is the main constraint in the setting of statistical learning described in the text?\\nA) Perfect observation of the $Y$-part of the sample\\nB) Communication of the $Y$-part of the sample at a finite bit rate\\nC) The predictor must be a linear function of $X$\\nD) The predictor must be a non-parametric function of $X$', '5. In the example of nonparametric regression in Gaussian noise, what is the main objective?\\nA) To estimate the mean of the Gaussian noise\\nB) To construct a predictor of the random variable $Y$ as a function of $X$ in Gaussian noise\\nC) To estimate the correlation between $X$ and $Y$ in Gaussian noise\\nD) To estimate the variance of the Gaussian noise'] ['1', 'B', 'B', 'A', 'B', 'B', 'B']\n",
            "questions, correct_answers  ['A) Random link failures\\nB) Non-random link failures\\nC) Fixed link failures\\nD) Gradual link failures', 'What is the main factor in determining the probability of error or communication failure in a link?\\n\\nA) Signal-to-noise ratio (SNR)\\nB) Costs\\nC) Constraints\\nD) Power', 'Which of the following is NOT a preliminary issue addressed in the paper?\\n\\nA) Model the network as a random topology\\nB) Establish necessary and sufficient conditions for mean square sense (mss) and almost sure (a.s.) convergence of average consensus\\nC) Show that a necessary and sufficient condition for both mss and a.s. convergence is for the algebraic connectivity of the mean graph describing the network topology to be strictly positive\\nD) Develop a new consensus algorithm', 'Which of the following is NOT a resource that sensors and networks operate under scarce conditions?\\n\\nA) Power\\nB) Data rate\\nC) Communication\\nD) Computational resources', 'What is the primary objective of the topology design problem addressed in the paper?\\n\\nA) Minimizing the probability of link failure\\nB) Maximizing the rate of convergence of average consensus\\nC) Minimizing the communication cost\\nD) Maximizing the number of sensors in the network', 'According to the paper, which of the following is a necessary and sufficient condition for both mean square sense (mss) and almost sure (a.s.) convergence of average consensus?\\nA) The algebraic connectivity of the mean graph describing the network topology is strictly positive\\nB) The signal-to-noise ratio (SNR) is maximized\\nC) The communication cost is minimized\\nD) The probability of link failure is minimized'] ['A', 'A', 'D', 'D', 'B', 'A']\n",
            "questions, correct_answers  [\"A) The Nile River is the longest river in the world.\\nB) The Amazon River is the longest river in Africa.\\nC) The Congo River is the world's second-longest river.\\nD) The Niger River is the longest river in Africa.\", 'A) The Nile River flows through Asia.\\nB) The Nile River flows through Europe.\\nC) The Nile River flows through Africa.\\nD) The Nile River flows through South America.', 'A) The shortest path problem is not considered under partial monitoring models.\\nB) The decision maker can choose a path between two distinguished vertices in each round.\\nC) The decision maker learns the weights of all edges after choosing a path.\\nD) The average cumulative loss of the algorithm is proportional to 1/\\\\sqrt{n}.', 'A) The algorithm has a linear complexity in the number of edges.\\nB) The algorithm has a quadratic complexity in the number of edges.\\nC) The algorithm has a constant complexity in the number of edges.\\nD) The algorithm has a logarithmic complexity in the number of edges.', 'A) The extension to the label efficient setting informs the decision maker about the weights of the edges not on the chosen path.\\nB) The extension to the label efficient setting informs the decision maker about the weights of the edges on the chosen path at a total of m << n time instances.\\nC) The extension to the label efficient setting informs the decision maker about the weights of the edges corresponding to a time-varying path.\\nD) The extension to the label efficient setting informs the decision maker about the weights of the edges on the chosen path at a total of n time instances.', 'A) The decision maker learns only the total weight of the chosen path in the multi-armed bandit setting.\\nB) The decision maker learns only the weights of the individual edges on the chosen path in the multi-armed bandit setting.\\nC) The decision maker learns only the weights of the edges on the chosen path at a total of m time instances in the multi-armed bandit setting.\\nD) The decision maker learns only the weights of the edges on the chosen path at a total of n time instances in the multi-armed bandit setting.', 'A) Applications to routing in packet switched networks are presented in the text.\\nB) Applications to routing in circuit switched networks are presented in the text.\\nC) Applications to routing in wireless networks are presented in the text.\\nD) Applications to routing in satellite networks are presented in the text.', 'A) The text discusses an algorithm that outperforms the best path in terms of average cumulative loss.\\nB) The text discusses an algorithm that performs worse than the best path in terms of average cumulative loss.\\nC) The text discusses an algorithm that performs the same as the best path in terms of average cumulative loss.\\nD) The text discusses an algorithm that performs randomly in terms of average cumulative loss.', 'A) The decision maker competes against a time-varying path in the generalized problem of tracking the best expert.\\nB) The decision maker competes against a time-invariant path in the generalized problem of tracking the best expert.\\nC) The decision maker competes against a fixed path in the generalized problem of tracking the best expert.\\nD) The decision maker competes against a random path in the generalized problem of tracking the best expert.', 'A) The text presents an algorithm that has a constant complexity in the number of rounds n.\\nB) The text presents an algorithm that has a linear complexity in the number of rounds n.\\nC) The text presents an algorithm that has a quadratic complexity in the number of rounds n.\\nD) The text presents an algorithm that has a logarithmic complexity in the number of rounds n.', \"A) The Amazon River is the world's second-longest river.\\nB) The Congo River is the world's second-longest river.\\nC) The Mississippi River is the world's second-longest river.\\nD) The Yangtze River is the world's second-longest river.\", 'A) The decision maker learns the weights of those edges that do not belong to the chosen path.\\nB) The decision maker learns the weights of those edges that belong to the chosen path.\\nC) The decision maker learns the weights of those edges that have the highest weight.\\nD) The decision maker learns the weights of those edges that have the lowest weight.', 'A) The text presents an algorithm that can be implemented with linear complexity in the number of edges.\\nB) The text presents an algorithm that can be implemented with quadratic complexity in the number of edges.\\nC) The text presents an algorithm that can be implemented with exponential complexity in the number of edges.\\nD) The text presents an algorithm that can be implemented with logarithmic complexity in the number of edges.', 'A) The text discusses a version of the multi-armed bandit setting for shortest path where the decision maker learns only the total weight of the chosen path.\\nB) The text discusses a version of the multi-armed bandit setting for shortest path where the decision maker learns only the weights of the individual edges on the path.\\nC) The text discusses a version of the multi-armed bandit setting for shortest path where the decision maker learns only the weights of the edges corresponding to the chosen path at a total of m time instances.\\nD) The text discusses a version of the multi-armed bandit setting for shortest path where the decision maker learns only the weights of the edges corresponding to the chosen path at a total of n time instances.', 'A) The text presents an algorithm that outperforms the best path in terms of average cumulative loss by a quantity that depends only polynomially on the number of edges of the graph.\\nB) The text presents an algorithm that outperforms the best path in terms of average cumulative loss by a quantity that depends only linearly on the number of edges of the graph.\\nC) The text presents an algorithm that outperforms the best path in terms of average cumulative loss by a quantity that depends only logarithmically on the number of edges of the graph.\\nD) The text presents an algorithm that outperforms the best path in terms of average cumulative loss by a quantity that depends only exponentially on the number of edges of the graph.', 'A) The text discusses an extension to the label efficient setting where the decision maker competes against a time-varying path.\\nB) The text discusses an extension to the label efficient setting where the decision maker competes against a fixed path.\\nC) The text discusses an extension to the label efficient setting where the decision maker competes against a random path.\\nD) The text discusses an extension to the label efficient setting where the decision maker competes against the best path.', 'A) The decision maker learns the weights of those edges that belong to the chosen path in the setting generalizing the multi-armed bandit problem.\\nB) The decision maker learns the weights of those edges that do not belong to the chosen path in the setting generalizing the multi-armed bandit problem.\\nC) The decision maker learns the weights of those edges that have the highest weight in the setting generalizing the multi-armed bandit problem.\\nD) The decision maker learns the weights of those edges that have the lowest weight in the setting generalizing the multi-armed bandit problem.', 'A) The text presents an algorithm that has a linear complexity in the number of rounds n and in the number of edges.\\nB) The text presents an algorithm that has a quadratic complexity in the number of rounds n and in the number of edges.\\nC) The text presents an algorithm that has a constant complexity in the number of rounds n and in the number of edges.\\nD) The text presents an algorithm that has a logarithmic complexity in the number of rounds n and in the number of edges.', 'A) The text discusses applications to routing in packet switched networks along with simulation results.\\nB) The text discusses applications to routing in circuit switched networks along with simulation results.\\nC) The text discusses applications to routing in wireless networks along with simulation results.\\nD) The text discusses applications to routing in satellite networks along with simulation results.'] ['A', 'C', 'D', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
            "questions, correct_answers  ['A) Ordinal regression is a type of learning that combines properties of classification and regression.\\nB) Ordinal regression is a type of learning that solely focuses on classification.\\nC) Ordinal regression is a type of learning that solely focuses on regression.\\nD) Ordinal regression is a type of learning that is not related to classification or regression.', 'A) NNRank is a method that outperforms neural network classification methods on several benchmark datasets.\\nB) NNRank is a method that underperforms neural network classification methods on several benchmark datasets.\\nC) NNRank is a method that performs similarly to neural network classification methods on several benchmark datasets.\\nD) NNRank is a method that has no relation to neural network classification methods.', 'A) NNRank is a generalization of the perceptron method for ordinal regression.\\nB) NNRank is a generalization of the backpropagation method for ordinal regression.\\nC) NNRank is a generalization of the decision tree method for ordinal regression.\\nD) NNRank is not a generalization of any existing method for ordinal regression.', 'A) NNRank is a useful tool for large-scale data processing tasks due to its ability to handle very large training datasets.\\nB) NNRank is not a useful tool for large-scale data processing tasks due to its inability to handle very large training datasets.\\nC) NNRank is a useful tool for large-scale data processing tasks due to its ability to process text data.\\nD) NNRank is not a useful tool for large-scale data processing tasks due to its slow prediction speed.', 'A) NNRank is a complementary tool for information retrieval and web page ranking tasks.\\nB) NNRank is not a complementary tool for information retrieval and web page ranking tasks.\\nC) NNRank is a complementary tool for collaborative filtering and protein ranking in Bioinformatics tasks.\\nD) NNRank is not a complementary tool for collaborative filtering and protein ranking in Bioinformatics tasks.'] ['A', 'A', 'A', 'A', 'C']\n",
            "questions, correct_answers  ['A) Monte Carlo Optimization (MCO)\\nB) Parametric machine-Learning (PL)\\nC) Blackbox optimization (BO)\\nD) Probability Collectives (PC)', 'Which of the following is not a major contribution of the paper?\\nA) Proving the mathematical identity between MCO and a broad class of PL problems\\nB) Introducing immediate sampling, a new version of the PC algorithm for blackbox optimization\\nC) Demonstrating the effectiveness of cross-validation and bagging in improving immediate sampling\\nD) Claiming that MCO and PL are completely unrelated', 'Which of the following statements about MCO is true according to the text?\\nA) MCO is only applicable to a narrow set of PL problems\\nB) MCO can potentially provide a new application domain for all broadly applicable PL techniques\\nC) MCO ignores the relationship between sample point locations and the associated values of the integrand\\nD) MCO is a completely separate field from PL and BO', 'According to the text, which of the following is a new version of the Probability Collectives (PC) algorithm?\\nA) Immediate sampling\\nB) Cross-validation\\nC) Bagging\\nD) Monte Carlo Optimization (MCO)', 'Which of the following is NOT a way to apply PL techniques to improve MCO, as described in the text?\\nA) Exploiting the sample location information\\nB) Forming a fit of the sample locations to the associated values of the integrand\\nC) Considering only the values of the integrand at the sample locations\\nD) Ignoring the relationship between sample point locations and the associated values of the integrand', 'What is NOT a major contribution of the paper according to the text?\\nA) Proving the mathematical identity between MCO and a broad class of PL problems\\nB) Introducing immediate sampling, a new version of the PC algorithm for blackbox optimization\\nC) Validating the way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling\\nD) Introducing a completely new optimization technique'] ['A', 'D', 'B', 'A', 'C', 'D']\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "No context correct answer percentage: 0 \n",
            "\n",
            "Original context correct answer percentage: 0 \n",
            "\n",
            "Knowledgegraph context correct answer percentage: 0 \n",
            "\n",
            "Reconstruckted text context correct answer percentage: 0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame({\n",
        "    'Input_Texts': input_string_so_far_list,\n",
        "    'Output_Graphs': all_kg_results,\n",
        "    'Output_Reconstructions': all_reconstruction_results, })\n",
        "\n",
        "\n",
        "# print(df)\n",
        "\n",
        "print(\"500 word sample evalution:\", \"\\n\")\n",
        "base_cap_500, original_cap_500, knowledgegraph_cap_500, reconstruction_cap_500 = evaluate_peformance(df, 5,\n",
        "                                                                                                     \"q_a_kg.parquet\")\n",
        "\n",
        "print(\"No context correct answer percentage:\", base_cap_500, \"\\n\")\n",
        "print(\"Original context correct answer percentage:\", original_cap_500, \"\\n\")\n",
        "print(\"Knowledgegraph context correct answer percentage:\", knowledgegraph_cap_500, \"\\n\")\n",
        "print(\"Reconstruckted text context correct answer percentage:\", reconstruction_cap_500, \"\\n\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (notebook_env)",
      "language": "python",
      "name": "notebook_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
