{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from scripts.style_generation import get_style_genre\n",
        "from scripts.first_n_words import get_first_n_words\n",
        "from scripts.llm import ask_LLM\n",
        "from scripts.kg_content import extract_kg_content\n",
        "from scripts.minhash_vector import create_minhash_vector\n",
        "from scripts.reconstruction_content import extract_reconstruction_content\n",
        "from scripts.evaluate import evaluate_peformance\n",
        "import scripts.prompts\n",
        "import scripts.api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset from Hugging Face\n",
        "dataset = pd.read_csv(\"dataset/ML-Arxiv-Papers.csv\")\n",
        "\n",
        "# Extract the 'train' split\n",
        "#train_dataset = dataset[\"train\"]\n",
        "\n",
        "# Create lists for titles and abstracts\n",
        "# titles = [entry['title'] for entry in train_dataset]\n",
        "# abstracts = [entry['abstract'] for entry in train_dataset]\n",
        "\n",
        "# Create a list with concatenated title and abstract for each sample\n",
        "concatenated_texts = dataset['abstract'] #[f\"{title} {abstract}\" for title, abstract in zip(titles, abstracts)]\n",
        "\n",
        "API_KEY = scripts.api_key.API_KEY\n",
        "\n",
        "\n",
        "stop_len = 5000\n",
        "\n",
        "all_kg_results = []\n",
        "all_reconstruction_results = []\n",
        "input_string_so_far_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<style_analysis>The given text is situated within the genre of academic writing, specifically in the realm of statistical learning. The format is that of a scholarly article or research paper, with a precise and technical language that is characteristic of such works.\n",
            "The writing style is formal, academic, and discipline-specific, utilizing complex syntactic structures and rich terminology that may be unfamiliar to readers outside the field. It maintains clarity and simplicity in its exposition, despite the complexity of the subject matter.\n",
            "In terms of rhythm and flow, the text unfolds through leisurely, intricate phrasing, which is appropriate for the genre and content. The pacing allows for the careful explanation of technical concepts and their interrelationships.\n",
            "The dominant tone of the text is impartial and authoritative, reflecting the objective nature of the subject matter. The authorial voice is distant, as is typical in academic writing, providing a comprehensive and detailed exposition of the topic.\n",
            "To replicate this style for new works across diverse topics, a literature expert could concisely convey the following critical stylistic features:\n",
            "1. Utilize a formal, academic writing style, maintaining clarity and simplicity in the exposition of complex concepts.\n",
            "2. Employ a rich, technical lexicon specific to the field of statistical learning.\n",
            "3. Adopt a leisurely, intricate phrasing that allows for the careful explanation of technical concepts and their interrelationships.\n",
            "4. Maintain an impartial and authoritative tone, providing a comprehensive and detailed exposition of the subject matter.\n",
            "5. Implement narrative techniques or rhetorical devices that are quintessential for capturing the style's core, such as the use of examples, illustrations, and the logical organization of ideas.</style_analysis>\n",
            "INPUT:   The problem of statistical learning is to construct a predictor of a random\n",
            "variable $Y$ as a function of a related random variable $X$ on the basis of an\n",
            "i.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\n",
            "predictors are drawn from some specified class, and the goal is to approach\n",
            "asymptotically the performance (expected loss) of the best predictor in the\n",
            "class. We consider the setting in which one has perfect observation of the\n",
            "$X$-part of the sample, while the $Y$-part has to be communicated at some\n",
            "finite bit rate. The encoding of the $Y$-values is allowed to depend on the\n",
            "$X$-values. Under suitable regularity conditions on the admissible predictors,\n",
            "the underlying family of probability distributions and the loss function, we\n",
            "give an information-theoretic characterization of achievable predictor\n",
            "performance in terms of conditional distortion-rate functions. The ideas are\n",
            "illustrated on the example of nonparametric regression in Gaussian noise.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "              'Statistical Learning': {\n",
            "                  'attributes': {\n",
            "                      'definition': 'A predictor of a random variable Y as a function of a related random variable X, based on an i.i.d. training sample from the joint distribution of (X,Y)',\n",
            "                      'goal': 'Approach the performance of the best predictor in the class',\n",
            "                      'setting': 'Perfect observation of X, while Y is communicated at finite bit rate',\n",
            "                      'encoding': 'Allowed to depend on X-values',\n",
            "                      'regularity_conditions': 'On admissible predictors, probability distributions, and loss function',\n",
            "                      'characterization': 'Information-theoretic in terms of conditional distortion-rate functions'\n",
            "                  }\n",
            "              },\n",
            "              'Nonparametric Regression in Gaussian Noise': {\n",
            "                  'relations': {\n",
            "                      'example_of': 'Statistical Learning'\n",
            "                  }\n",
            "              }\n",
            "<source_sentence_min_hash: [ 71718090  38167608    761466  22543064 133299020   7829423  42939786\n",
            "    128961   2709365  90094578   9939647  74243328  84054835  67312031\n",
            " 116293349  20727983] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Statistical Learning is a branch of predictive modeling that focuses on developing predictors for random variables. The primary goal of Statistical Learning is to approximate the performance of the best predictor in a given class. In this setting, the predictor is based on an independently and identically distributed (i.i.d.) training sample from the joint distribution of (X,Y).\n",
            "In Statistical Learning, perfect observation of the related random variable X is assumed, while the random variable Y is communicated at a finite bit rate. The encoding of Y is allowed to depend on the X-values. Regularity conditions are placed on admissible predictors, probability distributions, and the loss function. The characterization of Statistical Learning is information-theoretic, expressed in terms of conditional distortion-rate functions.\n",
            "A specific example of Statistical Learning is Nonparametric Regression in Gaussian Noise. Nonparametric Regression in Gaussian Noise is a type of predictive modeling that deals with the estimation of an unknown regression function in the presence of additive Gaussian noise. This approach falls under the umbrella of Statistical Learning, as it seeks to approximate the best predictor for the given problem.\n",
            "\n",
            "<style_analysis>The input text is a piece of technical writing, specifically in the field of sensor networks and communication. It falls under the genre of academic research or scientific analysis. The text is characterized by a formal, academic writing style that utilizes discipline-specific terminology and complex syntactic structures. The language is precise and technical, aiming to convey highly specialized information.\n",
            "The rhythm and flow of the text are leisurely and intricate, reflecting the complexity of the subject matter. The sentences are long and packed with information, which is typical of technical writing. This pacing aligns with the genre and content, ensuring clarity and comprehensiveness.\n",
            "The tone of the text is impartial and authoritative, reflecting the nature of the subject matter and the author's expertise in the field. The authorial voice is distant, as it is expected in a research paper where the focus is on presenting objective findings.\n",
            "For a literature expert to convey the stylistic essence of this text to an author wishing to replicate this style in new works across diverse topics, they might emphasize the following critical stylistic features:\n",
            "1. Sentence structure: The sentences are long, complex, and packed with technical information. This structure is essential for conveying specialized knowledge accurately.\n",
            "2. Lexicon: The text relies heavily on discipline-specific terminology, which is necessary for precise communication in the field of sensor networks and communication.\n",
            "3. Tone: The tone is impartial and authoritative. This reflects the nature of the subject matter and the author's expertise in the field.\n",
            "4. Implementation of narrative techniques or rhetorical devices: While not typically associated with technical writing, the use of rhetorical devices such as analogy or metaphor can help to simplify complex concepts for a wider audience, if the author chooses to do so.\n",
            "In summary, the input text is a piece of technical writing situated within the genre of academic research or scientific analysis. Its formal, academic writing style is characterized by precise, technical language, long and intricate sentences, an impartial, authoritative tone, and the implementation of complex syntactic structures.</style_analysis>\n",
            "INPUT:   In a sensor network, in practice, the communication among sensors is subject\n",
            "to:(1) errors or failures at random times; (3) costs; and(2) constraints since\n",
            "sensors and networks operate under scarce resources, such as power, data rate,\n",
            "or communication. The signal-to-noise ratio (SNR) is usually a main factor in\n",
            "determining the probability of error (or of communication failure) in a link.\n",
            "These probabilities are then a proxy for the SNR under which the links operate.\n",
            "The paper studies the problem of designing the topology, i.e., assigning the\n",
            "probabilities of reliable communication among sensors (or of link failures) to\n",
            "maximize the rate of convergence of average consensus, when the link\n",
            "communication costs are taken into account, and there is an overall\n",
            "communication budget constraint. To consider this problem, we address a number\n",
            "of preliminary issues: (1) model the network as a random topology; (2)\n",
            "establish necessary and sufficient conditions for mean square sense (mss) and\n",
            "almost sure (a.s.) convergence of average consensus when network links fail;\n",
            "and, in particular, (3) show that a necessary and sufficient condition for both\n",
            "mss and a.s. convergence is for the algebraic connectivity of the mean graph\n",
            "describing the network topology to be strictly positive. With these results, we\n",
            "formulate topology design, subject to random link failures and to a\n",
            "communication cost constraint, as a constrained convex optimization problem to\n",
            "which we apply semidefinite programming techniques. We show by an extensive\n",
            "numerical study that the optimal design improves significantly the convergence\n",
            "speed of the consensus algorithm and can achieve the asymptotic performance of\n",
            "a non-random network at a fraction of the communication cost.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "<kg>\n",
            "\n",
            "              'Sensor network communication': {\n",
            "                  'relations': {\n",
            "                      'subject_to': ['errors or failures at random times', 'costs', 'constraints']\n",
            "                  },\n",
            "                  'attributes': {\n",
            "                      'main_factor_in_determining_error_probability': 'signal-to-noise ratio (SNR)'\n",
            "                  }\n",
            "              },\n",
            "              'SNR': {\n",
            "                  'relations': {\n",
            "                      'main_factor_in_determining_error_probability': 'Sensor network communication'\n",
            "                  }\n",
            "              },\n",
            "              'Error probability': {\n",
            "                  'relations': {\n",
            "                      'proxy_for_SNR': 'Sensor network communication'\n",
            "                  }\n",
            "              },\n",
            "              'Average consensus': {\n",
            "                  'relations': {\n",
            "                      'convergence_rate_maximized_by_topology_design': 'Sensor network communication',\n",
            "                      'convergence_rate_improved_by_optimal_design': 'Sensor network communication'\n",
            "                  },\n",
            "                  'attributes': {\n",
            "                      'convergence_modes': ['mean square sense (mss)', 'almost sure (a.s.)']\n",
            "                  }\n",
            "              },\n",
            "              'Mean square sense (mss) convergence': {\n",
            "                  'relations': {\n",
            "                      'necessary_and_sufficient_condition': 'Positive algebraic connectivity of mean graph',\n",
            "                      'related_to': 'Average consensus'\n",
            "                  }\n",
            "              },\n",
            "              'Almost sure (a.s.) convergence': {\n",
            "                  'relations': {\n",
            "                      'necessary_and_sufficient_condition': 'Positive algebraic connectivity of mean graph',\n",
            "                      'related_to': 'Average consensus'\n",
            "                  }\n",
            "              },\n",
            "              'Positive algebraic connectivity': {\n",
            "                  'relations': {\n",
            "                      'necessary_and_sufficient_condition_for_both_mss_and_a.s._convergence': ['Mean square sense (mss) convergence', 'Almost sure (a.s.) convergence']\n",
            "                  }\n",
            "              },\n",
            "              'Mean graph': {\n",
            "                  'relations': {\n",
            "                      'describes_network_topology': 'Sensor network communication'\n",
            "                  }\n",
            "              },\n",
            "              'Topology design': {\n",
            "                  'relations': {\n",
            "                      'subject_to_random_link_failures': 'Sensor network communication',\n",
            "                      'subject_to_communication_cost_constraint': 'Sensor network communication',\n",
            "                      'convergence_rate_maximized_by': 'Average consensus',\n",
            "                      'improves_convergence_speed_of_consensus_algorithm': 'Sensor network communication'\n",
            "                  },\n",
            "                  'attributes': {\n",
            "                      'optimization_technique': 'Semidefinite programming'\n",
            "                  }\n",
            "              },\n",
            "              'Communication cost constraint': {\n",
            "                  'relations': {\n",
            "                      'subject_to': 'Topology design',\n",
            "                      'improves_asymptotic_performance_of_non-random_network_at_fraction_of_cost': 'Topology design'\n",
            "                  }\n",
            "              },\n",
            "              'Random topology': {\n",
            "                  'relations': {\n",
            "                      'modeled_network_as': 'Sensor network communication'\n",
            "                  }\n",
            "              },\n",
            "              'Necessary and sufficient condition': {\n",
            "                  'relations': {\n",
            "                      'for_both_mss_and_a.s._convergence': 'Positive algebraic connectivity',\n",
            "                      'related_to': ['Mean square sense (mss) convergence', 'Almost sure (a.s.) convergence']\n",
            "                  }\n",
            "              },\n",
            "              'Constrained convex optimization problem': {\n",
            "                  'relations': {\n",
            "                      'applied_to': 'Topology design'\n",
            "                  }\n",
            "              },\n",
            "              'Semidefinite programming techniques': {\n",
            "                  'relations': {\n",
            "                      'applied_to': 'Topology design'\n",
            "                  }\n",
            "              },\n",
            "              'Consensus algorithm': {\n",
            "                  'relations': {\n",
            "                      'convergence_speed_improved_by_optimal_design': 'Topology<source_sentence_min_hash: [ 6133174 40757083   761466 26799884 33277103  6881145 31366738 31699836\n",
            " 65066654 22783534  1409227 74243328 25367037 45058861 88401764 66262755] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Sensor network communication plays a crucial role in various applications, as it is subject to errors or failures at random times, costs, and constraints. One of the main factors in determining the error probability in such communication is the signal-to-noise ratio (SNR).\n",
            "In the context of sensor networks, the SNR is a critical factor that influences the error probability. Consequently, the error probability can be seen as a proxy for the SNR.\n",
            "Average consensus is a fundamental concept in distributed computing and is closely related to sensor network communication. The convergence rate of average consensus can be maximized by designing the network topology, and its convergence rate can be improved by optimal design. Average consensus can converge in two modes: mean square sense (mss) and almost sure (a.s.) convergence.\n",
            "For both mss and a.s. convergence, a necessary and sufficient condition is the presence of positive algebraic connectivity in the mean graph. The mean graph describes the network topology in a sensor network communication system.\n",
            "Topology design is a critical aspect of sensor network communication, as it is subject to random link failures and communication cost constraints. The convergence rate of average consensus can be maximized by optimal topology design. Furthermore, improved convergence speed of the consensus algorithm can be achieved through optimal topology design. The optimization technique used in topology design is semidefinite programming.\n",
            "Communication cost constraints are an essential consideration in topology design. Asymptotic performance of non-random networks can be improved at a fraction of the cost by considering communication cost constraints in topology design.\n",
            "Random topology can be used as a model for sensor network communication. In such cases, the network is modeled as a random topology.\n",
            "The necessary and sufficient condition for both mss and a.s. convergence in average consensus is the presence of positive algebraic connectivity. This condition is related to the convergence modes of average consensus.\n",
            "Topology design is often formulated as a constrained convex optimization problem, which can be solved using semidefinite programming techniques.\n",
            "The consensus algorithm is a key component in sensor network communication. Its convergence speed can be improved by optimal topology design.\n",
            "\n",
            "<style_analysis>The provided text is a technical piece that falls under the genre of academic research and analysis. It specifically discusses the online shortest path problem and proposes a solution algorithm for this problem. The writing style is formal, academic, and precise. The language is rich in discipline-specific terminology, and the text maintains simplicity and clarity.\n",
            "The rhythm of the text is steady, with a focus on concise, informative sentences. This pacing aligns with the genre, as it ensures that the complex ideas are presented clearly and logically.\n",
            "The dominant tone of the text is impartial and authoritative, which is expected in an academic research paper. The authorial voice is distant and objective, reflecting the nature of the content.\n",
            "For a literature expert to concisely convey the stylistic essence of this text to an author wishing to replicate this style in new works across diverse topics, they might emphasize the following critical stylistic features:\n",
            "1. Use of formal, academic language and precise terminology.\n",
            "2. Emphasis on clarity and simplicity, even when dealing with complex ideas.\n",
            "3. A steady, informative rhythm, with a focus on concise sentences.\n",
            "4. Implementation of impartial, authoritative tone and a distant, objective authorial voice.\n",
            "5. The use of narrative techniques or rhetorical devices would depend on the specific topic, but in this text, they are not a prominent feature. Instead, the focus is on presenting information logically and clearly.\n",
            "In conclusion, the text's writing style, rhythm, genre, and other distinctive features typify a formal, academic approach. The author effectively communicates complex ideas in a clear and concise manner, reflecting the nature of the content and the intended audience of academic researchers and analysts.</style_analysis>\n",
            "INPUT:   The on-line shortest path problem is considered under various models of\n",
            "partial monitoring. Given a weighted directed acyclic graph whose edge weights\n",
            "can change in an arbitrary (adversarial) way, a decision maker has to choose in\n",
            "each round of a game a path between two distinguished vertices such that the\n",
            "loss of the chosen path (defined as the sum of the weights of its composing\n",
            "edges) be as small as possible. In a setting generalizing the multi-armed\n",
            "bandit problem, after choosing a path, the decision maker learns only the\n",
            "weights of those edges that belong to the chosen path. For this problem, an\n",
            "algorithm is given whose average cumulative loss in n rounds exceeds that of\n",
            "the best path, matched off-line to the entire sequence of the edge weights, by\n",
            "a quantity that is proportional to 1/\\sqrt{n} and depends only polynomially on\n",
            "the number of edges of the graph. The algorithm can be implemented with linear\n",
            "complexity in the number of rounds n and in the number of edges. An extension\n",
            "to the so-called label efficient setting is also given, in which the decision\n",
            "maker is informed about the weights of the edges corresponding to the chosen\n",
            "path at a total of m << n time instances. Another extension is shown where the\n",
            "decision maker competes against a time-varying path, a generalization of the\n",
            "problem of tracking the best expert. A version of the multi-armed bandit\n",
            "setting for shortest path is also discussed where the decision maker learns\n",
            "only the total weight of the chosen path but not the weights of the individual\n",
            "edges on the path. Applications to routing in packet switched networks along\n",
            "with simulation results are also presented.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "\n",
            "'On-line Shortest Path Problem': {\n",
            "    'relations': {\n",
            "        'considered_under': 'Various Models of Partial Monitoring'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'A decision maker has to choose a path between two distinguished vertices in each round of a game, such that the loss of the chosen path (defined as the sum of the weights of its composing edges) be as small as possible. In a setting generalizing the multi-armed bandit problem, after choosing a path, the decision maker learns only the weights of those edges that belong to the chosen path.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Various Models of Partial Monitoring': {\n",
            "    'relations': {\n",
            "        'consider': 'The on-line shortest path problem'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'A framework for analyzing decision-making problems under uncertainty.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Average Cumulative Loss': {\n",
            "    'relations': {\n",
            "        'exceeds_that_of_the_best_path': True,\n",
            "        'proportional_to': '1/\\sqrt{n}',\n",
            "        'depends_only_polynomially_on': 'The number of edges of the graph'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'A measure of the performance of an algorithm for the on-line shortest path problem.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Algorithm for the On-line Shortest Path Problem': {\n",
            "    'relations': {\n",
            "        'given': 'For the on-line shortest path problem',\n",
            "        'implements': 'Linear complexity in the number of rounds n and in the number of edges'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'An algorithm that achieves a near-optimal average cumulative loss in n rounds.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Label Efficient Setting': {\n",
            "    'relations': {\n",
            "        'generalized_by': 'The on-line shortest path problem',\n",
            "        'informed_about_edge_weights': 'At a total of m << n time instances'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'A setting where the decision maker learns about the edge weights in a limited number of time instances.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Time-varying Path': {\n",
            "    'relations': {\n",
            "        'competed_against': 'The decision maker'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'A generalization of the problem of tracking the best expert.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Multi-armed Bandit Setting for Shortest Path': {\n",
            "    'relations': {\n",
            "        'discussed_in': 'The on-line shortest path problem',\n",
            "        'learns_only': 'The total weight of the chosen path but not the weights of the individual edges on the path'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'A version of the multi-armed bandit problem applied to the shortest path problem.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Routing in Packet Switched Networks': {\n",
            "    'relations': {\n",
            "        'application_of': 'The on-line shortest path problem'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'An application of the on-line shortest path problem in the context of packet switched networks.'\n",
            "    }\n",
            "},\n",
            "\n",
            "'Simulation Results': {\n",
            "    'relations': {\n",
            "        'presented_in': 'The on-line shortest path problem'\n",
            "    },\n",
            "    'attributes': {\n",
            "        'description': 'Simulation results for the on-line shortest path problem.'\n",
            "    }\n",
            "}\n",
            "\n",
            "<source_sentence_min_hash: [ 24568957   9924331   9024081  20022987  14019373   7829423  56607342\n",
            "   3587349  10677384  90094578  11836062   4170235 129802786   7369324\n",
            "  49382248   8604885] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "In the realm of decision-making under uncertainty, the 'On-line Shortest Path Problem' stands out as a significant challenge. This problem involves a decision-maker who must choose a path between two distinct vertices in each round of a game. The aim is to minimize the cumulative loss, which is defined as the sum of the weights of the chosen path's constituent edges. After selecting a path, the decision-maker learns only the weights of the edges that belong to the chosen path.\n",
            "The 'On-line Shortest Path Problem' is considered under the broader framework of 'Various Models of Partial Monitoring'. This framework serves as a generalized approach to analyzing decision-making problems under uncertainty.\n",
            "One measure of the performance of an algorithm for the 'On-line Shortest Path Problem' is the 'Average Cumulative Loss'. This measure is designed to quantify the efficiency of an algorithm by comparing it to the best possible path. The average cumulative loss is proportional to 1/\\sqrt{n} and depends only polynomially on the number of edges of the graph.\n",
            "An algorithm for the 'On-line Shortest Path Problem' has been developed that achieves a near-optimal average cumulative loss in n rounds. This algorithm boasts linear complexity in both the number of rounds (n) and the number of edges.\n",
            "In the 'Label Efficient Setting', the decision-maker learns about the edge weights in a limited number of time instances (m << n). This setting generalizes the 'On-line Shortest Path Problem' and represents a scenario where the decision-maker has access to only partial information.\n",
            "The 'Time-varying Path' problem can be viewed as a generalization of the problem of tracking the best expert. In this context, the decision-maker competes against a time-varying path.\n",
            "The 'Multi-armed Bandit Setting for Shortest Path' is a version of the multi-armed bandit problem applied to the shortest path problem. In this setting, the decision-maker learns only the total weight of the chosen path but not the weights of the individual edges on the path.\n",
            "The 'On-line Shortest Path Problem' has practical applications in 'Routing in Packet Switched Networks'. This problem is particularly relevant in the context of packet switched networks, where efficient routing is crucial for optimal performance.\n",
            "Simulation results for the 'On-line Shortest Path Problem' have been presented, providing valuable insights into the performance of various algorithms under different conditions and settings.\n",
            "\n",
            "<style_analysis>The text presents itself as a technical, academic work within the genre of computer science, specifically focusing on ordinal regression and machine learning. It falls under the sub-genre of speculative fiction, as it describes a hypothetical approach to adapt traditional neural networks for ordinal regression.\n",
            "The writing style is formal, precise, and utilizes discipline-specific terminology. The text employs complex syntactic structures, rich figurative language, and a lexicon that is exclusive to the field of machine learning and artificial intelligence.\n",
            "In terms of rhythm and flow, the text unfolds through leisurely, intricate phrasing, allowing for a comprehensive explanation of the methodology and its potential applications. The pacing aligns well with the technical nature of the content, ensuring clarity and comprehensiveness.\n",
            "The dominant tone of the text is impartial and authoritative, reflecting the objective, factual nature of the subject matter. The authorial voice is distant and informative, maintaining a professional demeanor throughout the piece.\n",
            "To guide an author wishing to replicate this style in new works across diverse topics, a literature expert could emphasize the following critical stylistic features:\n",
            "1. Sentence structure: Use complex, compound, and compound-complex sentences to convey technical information comprehensively.\n",
            "2. Lexicon: Incorporate discipline-specific terminology, ensuring that the language used is accurate and precise.\n",
            "3. Tone: Maintain an impartial, authoritative tone throughout the work, avoiding subjective opinions or personal anecdotes.\n",
            "4. Narrative techniques and rhetorical devices: Emphasize the use of logical arguments, empirical evidence, and clear explanations to support the proposed methodology.\n",
            "5. Online and batch learning capabilities: Highlight the advantages of traditional neural networks, such as their ability to learn in both online and batch modes, handle very large training datasets, and make rapid predictions.\n",
            "By incorporating these stylistic elements, an author can effectively capture the essence of the text's style and apply it to a wide range of topics within the realm of computer science and machine learning.</style_analysis>\n",
            "INPUT:   Ordinal regression is an important type of learning, which has properties of\n",
            "both classification and regression. Here we describe a simple and effective\n",
            "approach to adapt a traditional neural network to learn ordinal categories. Our\n",
            "approach is a generalization of the perceptron method for ordinal regression.\n",
            "On several benchmark datasets, our method (NNRank) outperforms a neural network\n",
            "classification method. Compared with the ordinal regression methods using\n",
            "Gaussian processes and support vector machines, NNRank achieves comparable\n",
            "performance. Moreover, NNRank has the advantages of traditional neural\n",
            "networks: learning in both online and batch modes, handling very large training\n",
            "datasets, and making rapid predictions. These features make NNRank a useful and\n",
            "complementary tool for large-scale data processing tasks such as information\n",
            "retrieval, web page ranking, collaborative filtering, and protein ranking in\n",
            "Bioinformatics.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "  'Ordinal Regression': {\n",
            "      'relations': {\n",
            "          'has_properties_of': ['Classification', 'Regression']\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'An important type of learning'\n",
            "      }\n",
            "  },\n",
            "  'Traditional Neural Network': {\n",
            "      'relations': {\n",
            "          'adapted_for': 'Ordinal Regression'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'learning_modes': ['Online', 'Batch'],\n",
            "          'large_training_datasets_handling': 'Yes',\n",
            "          'rapid_predictions': 'Yes',\n",
            "          'description': 'A generalization of the perceptron method'\n",
            "      }\n",
            "  },\n",
            "  'NNRank': {\n",
            "      'relations': {\n",
            "          'is_a': 'Traditional Neural Network',\n",
            "          'outperforms': 'Neural Network Classification Method',\n",
            "          'comparable_performance_with': ['Gaussian Process Ordinal Regression', 'Support Vector Machine Ordinal Regression'],\n",
            "          'applications': [\n",
            "              'Information Retrieval',\n",
            "              'Web Page Ranking',\n",
            "              'Collaborative Filtering',\n",
            "              'Protein Ranking in Bioinformatics'\n",
            "          ]\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A simple and effective approach for ordinal regression'\n",
            "      }\n",
            "  },\n",
            "  'Gaussian Process Ordinal Regression': {\n",
            "      'relations': {\n",
            "          'comparable_performance_with': 'NNRank'\n",
            "      }\n",
            "  },\n",
            "  'Support Vector Machine Ordinal Regression': {\n",
            "      'relations': {\n",
            "          'comparable_performance_with': 'NNRank'\n",
            "      }\n",
            "  },\n",
            "  'Information Retrieval': {\n",
            "      'relations': {\n",
            "          'utilizes': 'NNRank'\n",
            "      }\n",
            "  },\n",
            "  'Web Page Ranking': {\n",
            "      'relations': {\n",
            "          'utilizes': 'NNRank'\n",
            "      }\n",
            "  },\n",
            "  'Collaborative Filtering': {\n",
            "      'relations': {\n",
            "          'utilizes': 'NNRank'\n",
            "      }\n",
            "  },\n",
            "  'Protein Ranking in Bioinformatics': {\n",
            "      'relations': {\n",
            "          'utilizes': 'NNRank'\n",
            "      }\n",
            "  }\n",
            "<source_sentence_min_hash: [  6133174  34044574  67176199  49472071  33277103   7829423  24958943\n",
            "  18993971  67894626  14549103 126174866  74243328  14818304  32053883\n",
            " 138600072 152434034] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Ordinal regression is a crucial type of learning, combining elements of both classification and regression. Traditional neural networks are a generalization of the perceptron method and have been adapted for ordinal regression. These networks can handle large training datasets and provide rapid predictions.\n",
            "NNRank is a simple and effective approach for ordinal regression, falling under the category of traditional neural networks. It has been shown to outperform the Neural Network Classification Method and demonstrates comparable performance to Gaussian Process Ordinal Regression and Support Vector Machine Ordinal Regression. NNRank has various applications, including information retrieval, web page ranking, collaborative filtering, and protein ranking in bioinformatics.\n",
            "Gaussian Process Ordinal Regression and Support Vector Machine Ordinal Regression are two methods that have been found to have comparable performance to NNRank.\n",
            "In the realm of information retrieval, NNRank is utilized to improve search results and provide more accurate rankings. Similarly, web page ranking benefits from the use of NNRank, as it helps determine the relevance and importance of web pages in relation to specific queries or topics.\n",
            "Collaborative filtering, a technique commonly used in recommendation systems, also leverages NNRank to improve the accuracy and personalization of suggested items or content.\n",
            "Protein ranking in bioinformatics is another area where NNRank proves to be valuable. By analyzing and ranking proteins based on various factors, researchers can better understand protein interactions and functions, ultimately aiding in the discovery of new drugs and treatments.\n",
            "\n",
            "<style_analysis>The text under analysis is a scholarly piece situated within the academic journal genre. Its style is formal, academic, and characterized by discipline-specific terminology and complex syntactic structures. The rhythm of the text is consistent with its genre, unfolding in a leisurely, intricate manner that aligns with the technical nature of the content.\n",
            "The tone of the text is impartial and authoritative, reflecting the objective nature of the subject matter. The authorial voice is distant and introspective, focusing on the logical progression of ideas and the presentation of proofs and methodologies.\n",
            "To replicate the style of this text in new works, a literature expert could concisely convey the following stylistic features:\n",
            "1. Sentence structure: The text employs long, complex sentences that present multiple interconnected ideas. The expert might advise the author to maintain this structure to convey technical complexity.\n",
            "2. Lexicon: The text utilizes a rich vocabulary that includes discipline-specific terminology. The expert might suggest that the author familiarize themselves with the relevant terminology to ensure accuracy and clarity.\n",
            "3. Tone: The expert would likely emphasize the need to maintain an impartial and authoritative tone, as this conveys a sense of objectivity and credibility.\n",
            "4. Narrative techniques and rhetorical devices: The expert might point out that the text makes extensive use of logical reasoning and the presentation of proofs. The author wishing to replicate this style could be advised to prioritize the logical progression of ideas and the clear presentation of evidence and methodologies.\n",
            "In summary, the text under analysis is a formal, academic piece that employs a leisurely, intricate rhythm and an impartial, authoritative tone. To replicate this style, an author could focus on maintaining complex sentence structures, utilizing a rich vocabulary that includes discipline-specific terminology, and prioritizing logical reasoning and the clear presentation of evidence and methodologies.</style_analysis>\n",
            "INPUT:   This paper uncovers and explores the close relationship between Monte Carlo\n",
            "Optimization of a parametrized integral (MCO), Parametric machine-Learning\n",
            "(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\n",
            "contributions. First, we prove that MCO is mathematically identical to a broad\n",
            "class of PL problems. This identity potentially provides a new application\n",
            "domain for all broadly applicable PL techniques: MCO. Second, we introduce\n",
            "immediate sampling, a new version of the Probability Collectives (PC) algorithm\n",
            "for blackbox optimization. Immediate sampling transforms the original BO\n",
            "problem into an MCO problem. Accordingly, by combining these first two\n",
            "contributions, we can apply all PL techniques to BO. In our third contribution\n",
            "we validate this way of improving BO by demonstrating that cross-validation and\n",
            "bagging improve immediate sampling. Finally, conventional MC and MCO procedures\n",
            "ignore the relationship between the sample point locations and the associated\n",
            "values of the integrand; only the values of the integrand at those locations\n",
            "are considered. We demonstrate that one can exploit the sample location\n",
            "information using PL techniques, for example by forming a fit of the sample\n",
            "locations to the associated values of the integrand. This provides an\n",
            "additional way to apply PL techniques to improve MCO.\n",
            "\n",
            "-----\n",
            "<segment 1>\n",
            "\n",
            "\n",
            "  'Monte Carlo Optimization of a parametrized integral (MCO)': {\n",
            "      'relations': {\n",
            "          'is_mathematically_identical_to': 'a broad class of Parametric machine-Learning (PL) problems'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A mathematical optimization technique'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Parametric machine-Learning (PL)': {\n",
            "      'relations': {\n",
            "          'has_mathematical_identity_with': 'Monte Carlo Optimization of a parametrized integral (MCO)'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A class of machine learning techniques that involve learning from a set of input-output pairs'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'blackbox' or `oracle'-based optimization (BO)': {\n",
            "      'relations': {\n",
            "          'is_transformed_by': 'Immediate sampling'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'An optimization technique where the objective function is not explicitly known, and the optimizer can only query the function at specific points'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Immediate sampling': {\n",
            "      'relations': {\n",
            "          'is_a_new_version_of': 'Probability Collectives (PC) algorithm',\n",
            "          'transforms': 'blackbox optimization (BO) into an MCO problem'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'An algorithm for blackbox optimization that transforms the original BO problem into an MCO problem'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Probability Collectives (PC) algorithm': {\n",
            "      'relations': {\n",
            "          'has_new_version': 'Immediate sampling'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'An algorithm for blackbox optimization'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Cross-validation': {\n",
            "      'relations': {\n",
            "          'improves': 'Immediate sampling'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A technique for assessing the performance of a machine learning model by dividing the data into subsets and using one subset to train the model and the other to validate it'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Bagging': {\n",
            "      'relations': {\n",
            "          'improves': 'Immediate sampling'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'An ensemble machine learning method that involves training multiple models on different subsets of the data and then combining their predictions'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Conventional MC and MCO procedures': {\n",
            "      'relations': {\n",
            "          'ignore': 'the relationship between the sample point locations and the associated values of the integrand'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'Standard procedures for Monte Carlo and MCO optimization'\n",
            "\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'Sample location information': {\n",
            "      'relations': {\n",
            "          'can_be_exploited_by': 'Parametric machine-Learning (PL) techniques'\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'Information about the locations of the sample points in an optimization problem'\n",
            "      }\n",
            "  },\n",
            "\n",
            "  'PL techniques': {\n",
            "      'relations': {\n",
            "          'can_exploit': 'sample location information',\n",
            "          'can_be_applied_to': ['blackbox optimization (BO)', 'Monte Carlo Optimization of a parametrized integral (MCO)']\n",
            "      },\n",
            "      'attributes': {\n",
            "          'description': 'A class of machine learning techniques that involve learning from a set of input-output pairs'\n",
            "\n",
            "      }\n",
            "  },\n",
            "\n",
            "<source_sentence_min_hash: [ 19667641 110676249   7034219   6794115  10405434  49829016  31366738\n",
            "  63416529  48596860  14650532 101042331  10913943  33479172  32685091\n",
            "  40988719  79205732] >\n",
            "</segment 1>\n",
            "\n",
            "\n",
            "\n",
            "Monte Carlo Optimization (MCO) is a mathematical optimization technique that is mathematically identical to a broad class of Parametric machine-Learning (PL) problems. PL techniques, a class of machine learning methods, involve learning from a set of input-output pairs. These techniques can exploit sample location information, which refers to the locations of sample points in an optimization problem. PL techniques can be applied to both blackbox optimization (BO) and MCO problems.\n",
            "BO is an optimization technique where the objective function is not explicitly known, and the optimizer can only query the function at specific points. Immediate sampling is an algorithm for blackbox optimization that transforms the original BO problem into an MCO problem. It is a new version of the Probability Collectives (PC) algorithm, which is another algorithm for blackbox optimization.\n",
            "Cross-validation and Bagging are techniques that can improve Immediate sampling. Cross-validation assesses the performance of a machine learning model by dividing the data into subsets and using one subset to train the model and the other to validate it. Bagging, on the other hand, is an ensemble machine learning method that involves training multiple models on different subsets of the data and then combining their predictions.\n",
            "Conventional MC and MCO procedures, however, ignore the relationship between the sample point locations and the associated values of the integrand. In contrast, PL techniques can exploit sample location information, making them more effective in solving optimization problems.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for input_text in concatenated_texts[:5]:\n",
        "\n",
        "    writing_style = get_style_genre(get_first_n_words(input_text, 1000))\n",
        "\n",
        "    # sentences= text_to_sentences(input_text)\n",
        "    # sentences =sentences_to_large_strings(sentences)\n",
        "    sentences = [input_text]\n",
        "    # print(sentences)\n",
        "    # continue\n",
        "    current_kg = []\n",
        "    current_kg.append(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
        "    print(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
        "    segment_nr = 1\n",
        "    reconstruction_so_far = \"\"\n",
        "    input_string_so_far = \"\"\n",
        "    for sentence in sentences:\n",
        "        input_string_so_far += sentence\n",
        "        if len(input_string_so_far) > stop_len:\n",
        "            break\n",
        "        print(\"INPUT:\", sentence)\n",
        "        print(\"-----\")\n",
        "        '''\n",
        "        prompt=\"\"\"INPUT_TEXT:\n",
        "        \"\"\"+sentence+\"\"\"\n",
        "        INSTRUCTION:\n",
        "        Paraphrase the given input text so that every statement is rephrased into sentences that contain only three to ten words each. Use a simple structure and make sure to retain all information, names, numbers, and dates from the original text, without losing any information. The output text should consist exclusively of factual, neutrally phrased sentences that are three to ten words long. All information must be preserved, but without any artistic nuances. Direct speech in the source text should not be replicated as such, but it should be laid out in short sentences who said or did what in which order, ensuring a neutral, information-rich text.\"\"\"\n",
        "  \n",
        "        reply = ask_LLM ('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', \"You are a very smart very intelligence assistant who is very helpful.\", input_text , API_KEY ,temperature=0.5,top_p=0.95,max_tokens=1000, frequency_penalty=1.1,presence_penalty=1.1)\n",
        "        '''\n",
        "\n",
        "        # Determine the slice of the last 50 elements (if the list has more than 50 elements)\n",
        "        current_kg_context = current_kg[-50:] if len(current_kg) > 50 else current_kg\n",
        "\n",
        "        # Concatenate the elements into a single string\n",
        "        current_kg_context = ' '.join(current_kg_context)\n",
        "        text = scripts.prompts.KG_format_example_prompt(current_kg_context, sentence)\n",
        "\n",
        "        for i in range(2):\n",
        "            knowledge_graph_segment = ask_LLM('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
        "                                              \"You are a very smart very intelligence assistant who is very helpful.\",\n",
        "                                              text, API_KEY, temperature=0.5, top_p=0.95, max_tokens=1000,\n",
        "                                              frequency_penalty=1.1, presence_penalty=1.1)\n",
        "            if not (extract_kg_content(knowledge_graph_segment) == None):\n",
        "                break\n",
        "        try:\n",
        "            current_kg.append(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
        "                knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
        "                create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "            print(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
        "                knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
        "                create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "        except:\n",
        "            current_kg.append(\n",
        "                \"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
        "                    create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "            print(\"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
        "                create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
        "\n",
        "        prompt = scripts.prompts.KG_reconstruction_prompt(reconstruction_so_far, current_kg)\n",
        "        for i in range(2):\n",
        "            next_reconstruction = ask_LLM('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
        "                                          \"You are a very smart very intelligence assistant who is very helpful.\",\n",
        "                                          prompt, API_KEY, temperature=0.5, top_p=0.95, max_tokens=4000,\n",
        "                                          frequency_penalty=1.1, presence_penalty=1.1)\n",
        "            if not (extract_reconstruction_content(next_reconstruction) == None):\n",
        "                break\n",
        "\n",
        "        reconstruction_so_far += extract_reconstruction_content(next_reconstruction)\n",
        "        print(extract_reconstruction_content(next_reconstruction))\n",
        "        segment_nr += 1\n",
        "    all_kg_results.append(current_kg)\n",
        "    all_reconstruction_results.append(reconstruction_so_far)\n",
        "    input_string_so_far_list.append(input_string_so_far)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500 word sample evalution: \n",
            "\n",
            "questions, correct_answers  [] []\n",
            "questions, correct_answers  ['A) Random link failures\\nB) Non-random link failures\\nC) Perfect link communication\\nD) Delayed link communication', 'What is the main factor that determines the probability of error or communication failure in a link?\\nA) Signal-to-noise ratio (SNR)\\nB) Network topology\\nC) Communication budget constraint\\nD) Algebraic connectivity', 'Which of the following is NOT a preliminary issue addressed in the text?\\nA) Modeling the network as a random topology\\nB) Establishing necessary and sufficient conditions for mean square sense (mss) and almost sure (a.s.) convergence of average consensus when network links fail\\nC) Showing that a necessary and sufficient condition for both mss and a.s. convergence is for the algebraic connectivity of the mean graph describing the network topology to be strictly positive\\nD) Proposing a topology design algorithm that guarantees perfect link communication', 'Which optimization technique is applied to the topology design problem?\\nA) Linear programming\\nB) Integer programming\\nC) Semidefinite programming\\nD) Nonlinear programming', 'What is the primary goal of the topology design problem?\\nA) Minimizing the probability of error or communication failure\\nB) Maximizing the rate of convergence of average consensus\\nC) Reducing the communication budget constraint\\nD) Ensuring perfect link communication', 'According to the numerical study, what is the significant improvement achieved by the optimal design of the topology?\\nA) Increased link communication costs\\nB) Decreased convergence speed of the consensus algorithm\\nC) Increased communication budget constraint\\nD) Achieved asymptotic performance of a non-random network at a fraction of the communication cost'] ['A', 'A', 'D', 'C', 'B', 'D']\n",
            "questions, correct_answers  ['A) The Nile River is the longest river in the world.\\nB) The Amazon River is the longest river in Africa.\\nC) The Congo River is the second-longest river in the world.\\nD) The Niger River is the second-longest river in Africa.', 'A) The Nile River is the only river mentioned in the passage.\\nB) The Nile River and the Amazon River are the only two rivers mentioned in the passage.\\nC) The Nile River, the Amazon River, the Congo River, and the Niger River are all mentioned in the passage.\\nD) The passage does not mention any other rivers besides the Nile River.', 'A) The passage is primarily about the Nile River.\\nB) The passage is primarily about the Amazon River.\\nC) The passage is primarily about the shortest path problem in a graph.\\nD) The passage is primarily about the multi-armed bandit problem.', 'A) The decision maker learns the weights of all edges in the graph after choosing a path.\\nB) The decision maker only learns the weights of the edges that belong to the chosen path.\\nC) The decision maker learns the weights of the edges that do not belong to the chosen path.\\nD) The decision maker never learns the weights of any edges in the graph.', \"A) The algorithm's average cumulative loss in n rounds is proportional to 1/\\\\sqrt{n}.\\nB) The algorithm's average cumulative loss in n rounds is proportional to 1/n.\\nC) The algorithm's average cumulative loss in n rounds is proportional to 1/n^2.\\nD) The algorithm's average cumulative loss in n rounds is proportional to 1/n^(1/2).\", 'A) The passage presents a linear complexity algorithm for the shortest path problem.\\nB) The passage presents an exponential complexity algorithm for the shortest path problem.\\nC) The passage presents a polynomial complexity algorithm for the shortest path problem.\\nD) The passage does not discuss the complexity of the algorithm.', 'A) The passage discusses an extension of the algorithm to the label efficient setting.\\nB) The passage discusses an extension of the algorithm to the multi-armed bandit setting.\\nC) The passage discusses an extension of the algorithm to the time-varying path setting.\\nD) The passage does not discuss any extensions of the algorithm.', 'A) The passage presents a version of the multi-armed bandit setting for the shortest path problem where the decision maker learns the total weight of the chosen path.\\nB) The passage presents a version of the multi-armed bandit setting for the shortest path problem where the decision maker learns the weights of the individual edges on the path.\\nC) The passage does not discuss any versions of the multi-armed bandit setting for the shortest path problem.\\nD) The passage presents a version of the multi-armed bandit setting for the shortest path problem where the decision maker learns the weights of the edges corresponding to the chosen path at a total of m << n time instances.', 'A) The passage presents an algorithm that can be implemented with linear complexity in the number of rounds n and in the number of edges.\\nB) The passage presents an algorithm that can be implemented with quadratic complexity in the number of rounds n and in the number of edges.\\nC) The passage presents an algorithm that can be implemented with exponential complexity in the number of rounds n and in the number of edges.\\nD) The passage does not discuss the complexity of the algorithm.', 'A) The passage discusses applications of the algorithm to routing in packet switched networks and presents simulation results.\\nB) The passage discusses applications of the algorithm to routing in circuit switched networks and presents simulation results.\\nC) The passage does not discuss any applications of the algorithm.\\nD) The passage discusses applications of the algorithm to routing in both packet switched networks and circuit switched networks and presents simulation results.'] ['C', 'C', 'C', 'B', 'A', 'A', 'C', 'D', 'A', 'A']\n",
            "questions, correct_answers  ['', '', '', '', ''] ['1', '2', '3', '4', '5']\n",
            "questions, correct_answers  ['What is the primary focus of the paper?\\nA) A study of the Nile River\\nB) A comparison of machine learning and blackbox optimization\\nC) An exploration of the relationship between Monte Carlo Optimization and Parametric machine-Learning\\nD) An analysis of the economic impact of the Amazon River', 'Which of the following is NOT a contribution of the paper?\\nA) Proving that MCO is mathematically identical to a broad class of PL problems\\nB) Introducing immediate sampling, a new version of the Probability Collectives algorithm\\nC) Demonstrating that cross-validation and bagging improve immediate sampling\\nD) Proposing a new method for predicting stock market trends', 'According to the text, which technique is NOT directly addressed in the paper?\\nA) Monte Carlo Optimization (MCO)\\nB) Parametric machine-Learning (PL)\\nC) Blackbox optimization (BO)\\nD) Gradient descent optimization', 'What is the primary advantage of the identity between MCO and PL?\\nA) It allows for the use of PL techniques in MCO problems\\nB) It simplifies the mathematical complexity of MCO problems\\nC) It provides a new application domain for all broadly applicable PL techniques\\nD) It improves the efficiency of MCO algorithms', 'Immediate sampling is a new version of which algorithm?\\nA) Gradient descent\\nB) Probability Collectives (PC)\\nC) Newton-Raphson method\\nD) Simulated annealing', 'Which of the following is NOT a way the paper suggests improving MCO?\\nA) Applying cross-validation and bagging techniques\\nB) Exploiting the relationship between sample point locations and the associated values of the integrand\\nC) Using a genetic algorithm for optimization\\nD) Forming a fit of the sample locations to the associated values of the integrand', 'According to the text, what do conventional MC and MCO procedures have in common?\\nA) They both use the Probability Collectives algorithm\\nB) They both ignore the relationship between the sample point locations and the associated values of the integrand\\nC) They both rely on gradient descent optimization\\nD) They both require a significant amount of computational resources', 'What does the paper suggest can be exploited using PL techniques to improve MCO?\\nA) The relationship between sample point locations and the associated values of the integrand\\nB) The inherent randomness of MCO problems\\nC) The computational complexity of PL techniques\\nD) The similarity between MCO and PL problems'] ['C', 'D', 'D', 'A', 'B', 'C', 'B', 'A']\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................correct_answers_short............\n",
            "[]\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "....................base_cap......................\n",
            "None\n",
            "correct_answers_short, original_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, knowledgegraph_context_answers_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "correct_answers_short, reconstruction_context_answer_short [] []\n",
            "...............yes,evaluate_answers_is_calling ..............\n",
            "No context correct answer percentage: 0 \n",
            "\n",
            "Original context correct answer percentage: 0 \n",
            "\n",
            "Knowledgegraph context correct answer percentage: 0 \n",
            "\n",
            "Reconstruckted text context correct answer percentage: 0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame({\n",
        "    'Input_Texts': input_string_so_far_list,\n",
        "    'Output_Graphs': all_kg_results,\n",
        "    'Output_Reconstructions': all_reconstruction_results, })\n",
        "\n",
        "\n",
        "# print(df)\n",
        "\n",
        "print(\"500 word sample evalution:\", \"\\n\")\n",
        "base_cap_500, original_cap_500, knowledgegraph_cap_500, reconstruction_cap_500 = evaluate_peformance(df, 5,\n",
        "                                                                                                     \"q_a_kg.parquet\")\n",
        "\n",
        "print(\"No context correct answer percentage:\", base_cap_500, \"\\n\")\n",
        "print(\"Original context correct answer percentage:\", original_cap_500, \"\\n\")\n",
        "print(\"Knowledgegraph context correct answer percentage:\", knowledgegraph_cap_500, \"\\n\")\n",
        "print(\"Reconstruckted text context correct answer percentage:\", reconstruction_cap_500, \"\\n\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (notebook_env)",
      "language": "python",
      "name": "notebook_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
