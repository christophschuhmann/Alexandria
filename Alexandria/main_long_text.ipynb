{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.style_generation import get_style_genre\n",
    "from scripts.first_n_words import get_first_n_words\n",
    "from scripts.llm import ask_LLM\n",
    "from scripts.kg_content import extract_kg_content\n",
    "from scripts.minhash_vector import create_minhash_vector\n",
    "from scripts.reconstruction_content import extract_reconstruction_content\n",
    "from scripts.evaluate import evaluate_peformance\n",
    "import scripts.prompts\n",
    "import scripts.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "dataset = pd.read_csv(\"data/ML-Arxiv-Papers.csv\")\n",
    "rows, columns = dataset.shape\n",
    "# Extract the 'train' split\n",
    "#train_dataset = dataset[\"train\"]\n",
    "\n",
    "# Create lists for titles and abstracts\n",
    "# titles = [entry['title'] for entry in train_dataset]\n",
    "# abstracts = [entry['abstract'] for entry in train_dataset]\n",
    "\n",
    "# Create a list with concatenated title and abstract for each sample\n",
    "concatenated_texts = dataset['abstract'] #[f\"{title} {abstract}\" for title, abstract in zip(titles, abstracts)]\n",
    "\n",
    "API_KEY = scripts.api_key.API_KEY\n",
    "\n",
    "\n",
    "stop_len = 50000 #5000\n",
    "\n",
    "model_name = \"meta-llama/Llama-3-70b-chat-hf\"\n",
    "#\"meta-llama/Llama-3-70b-chat-hf\"\n",
    "#\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
    "system_prompt = \"You are a very smart very intelligence assistant who is very helpful.\"\n",
    "\n",
    "all_kg_results = []\n",
    "all_reconstruction_results = []\n",
    "input_string_so_far_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117592"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KG_construction_and_reconstruction(input_text, model):\n",
    "    writing_style = get_style_genre(get_first_n_words(input_text, len(input_text)), model_name, system_prompt) #len(input_text) 1000\n",
    "    sentences = [input_text]\n",
    "    current_kg = []\n",
    "    current_kg.append(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
    "    segment_nr = 1\n",
    "    reconstruction_so_far = \"\"\n",
    "    input_string_so_far = \"\"\n",
    "    for sentence in sentences:\n",
    "        input_string_so_far += sentence\n",
    "        if len(input_string_so_far) > stop_len:\n",
    "            break\n",
    "        current_kg_context = current_kg[-50:] if len(current_kg) > 50 else current_kg\n",
    "\n",
    "            # Concatenate the elements into a single string\n",
    "        current_kg_context = ' '.join(current_kg_context)\n",
    "\n",
    "        text = scripts.prompts.KG_format_example_prompt(current_kg_context, sentence)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            for i in range(2):\n",
    "                knowledge_graph_segment = ask_LLM(model_name, system_prompt,text, API_KEY, temperature=0.5, top_p=0.95, max_tokens=1000,\n",
    "                                                    frequency_penalty=1.1, presence_penalty=1.1)\n",
    "                if not (extract_kg_content(knowledge_graph_segment) == None):\n",
    "                    break\n",
    "            try:\n",
    "                current_kg.append(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "                        knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "                        create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "                print(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "                        knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "                        create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "            except:\n",
    "                current_kg.append(\n",
    "                        \"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "                            create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "                print(\"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "                        create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "\n",
    "            prompt = scripts.prompts.KG_reconstruction_prompt(reconstruction_so_far, current_kg)\n",
    "            for i in range(2):\n",
    "                next_reconstruction = ask_LLM(model_name,\n",
    "                                                \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "                                                prompt, API_KEY, temperature=0.5, top_p=0.95, max_tokens=4000,\n",
    "                                                frequency_penalty=1.1, presence_penalty=1.1)\n",
    "                if not (extract_reconstruction_content(next_reconstruction) == None):\n",
    "                    break\n",
    "\n",
    "            reconstruction_so_far += extract_reconstruction_content(next_reconstruction)\n",
    "                #print(reconstruction_so_far)\n",
    "\n",
    "            print(extract_reconstruction_content(next_reconstruction))\n",
    "            segment_nr += 1\n",
    "\n",
    "            #all_kg_results.append(current_kg)\n",
    "            #print(\"....................start....................................\")\n",
    "            #print(current_kg.split(\"<source_sentence_min_hash:\"))\n",
    "\n",
    "            #print(\"...............current kg........................\")\n",
    "            #print(current_kg)\n",
    "\n",
    "            #kg_String = ''.join(current_kg)\n",
    "        \n",
    "        except:\n",
    "            print(\"No Kg found\")\n",
    "            \n",
    "#         try:\n",
    "#             all_kg_results.append(current_kg)\n",
    "\n",
    "#                 #print(\".....................current kg end.........................\")\n",
    "#                 #all_reconstruction_results.append(reconstruction_so_far)\n",
    "#                 #print(reconstruction_so_far.split(\"<source_sentence_min_hash:\")[0])\n",
    "#                 #reconstruction_String = ''.join(reconstruction_so_far)\n",
    "#             all_reconstruction_results.append(reconstruction_so_far)\n",
    "#                 #print(\"....................end....................................\")\n",
    "\n",
    "#             input_string_so_far_list.append(input_string_so_far)\n",
    "        \n",
    "#         except:\n",
    "#             print(\"Pass because of no Kg found\")\n",
    "            \n",
    "#     return input_string_so_far_list, all_kg_results, all_reconstruction_results\n",
    "    return input_string_so_far, current_kg, reconstruction_so_far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_long_text(text, segment_length):\n",
    "    words = text.split()\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    word_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        current_segment.append(word)\n",
    "        word_count += 1\n",
    "\n",
    "        if word_count >= segment_length:\n",
    "            segments.append(' '.join(current_segment))\n",
    "            current_segment = []\n",
    "            word_count = 0\n",
    "\n",
    "    # Add any remaining words as a last segment\n",
    "    if current_segment:\n",
    "        #segments.append(current_segment)\n",
    "        segments.append(' '.join(current_segment))\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_of_lists(list_of_lists):\n",
    "    flattened_list = [item for sublist in list_of_lists for item in sublist]\n",
    "    return ''.join(flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "985\n",
      "The problem of statistical learning is to construct a predictor of a random variable $Y$ as a function of a related random variable $X$ on the basis of an i.i.d. training sample from the joint distribution of $(X,Y)$. Allowable predictors are drawn from some specified class, and the goal is to approach asymptotically the performance (expected loss) of the best predictor in the class. We consider the setting in which one has perfect observation of the $X$-part of the sample, while the $Y$-part has to be communicated at some finite bit rate. The encoding of the $Y$-values is allowed to\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Statistical Learning Problem': {\n",
      "  'relations': {\n",
      "    'defined_by': 'Constructing a predictor of a random variable',\n",
      "    'involves': 'Random variables X and Y',\n",
      "    'based_on': 'i.i.d. training sample'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Constructing a predictor of a random variable Y as a function of X',\n",
      "    'goal': 'Approach asymptotically the performance of the best predictor'\n",
      "  }\n",
      "},\n",
      "\n",
      "'i.i.d. Training Sample': {\n",
      "  'relations': {\n",
      "    'drawn_from': 'Joint distribution of (X,Y)'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'type': 'Independent and identically distributed'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Joint Distribution of (X,Y)': {\n",
      "  'relations': {\n",
      "    'involves': 'Random variables X and Y'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Distribution of X and Y'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Random Variable X': {\n",
      "  'relations': {\n",
      "    'part_of': 'Joint distribution of (X,Y)',\n",
      "    'observed': 'Perfectly'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Random variable X'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Random Variable Y': {\n",
      "  'relations': {\n",
      "    'part_of': 'Joint distribution of (X,Y)',\n",
      "    'communicated_at': 'Finite bit rate'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Random variable Y'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Predictor': {\n",
      "  'relations': {\n",
      "    'drawn_from': 'Specified class',\n",
      "    'goal': 'Approach asymptotically the performance of the best predictor'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Function of X'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Encoding of Y-values': {\n",
      "  'relations': {\n",
      "    'allowed_to': 'Be communicated at finite bit rate'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Encoding of Y-values'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [ 89188865  38167608  91521943  22543064 133299020   7829423  42939786\n",
      "  22419451   2709365  90094578   9939647  74243328  84054835 124284561\n",
      " 125287739  45231480] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "In the context of statistical learning problems, a crucial aspect is the construction of a predictor of a random variable Y as a function of X. This involves random variables X and Y, which are part of a joint distribution. The joint distribution of (X, Y) is the underlying distribution of X and Y.\n",
      "\n",
      "To approach the performance of the best predictor, a predictor is drawn from a specified class. The goal is to asymptotically approach the performance of the best predictor. In this process, an i.i.d. training sample is used, which is drawn from the joint distribution of (X, Y). This training sample is independent and identically distributed.\n",
      "\n",
      "Random variable X is observed perfectly and is part of the joint distribution of (X, Y). On the other hand, random variable Y is also part of the joint distribution of (X, Y) and is communicated at a finite bit rate. The encoding of Y-values is allowed to be communicated at this finite bit rate.\n",
      "\n",
      "\n",
      "depend on the $X$-values. Under suitable regularity conditions on the admissible predictors, the underlying family of probability distributions and the loss function, we give an information-theoretic characterization of achievable predictor performance in terms of conditional distortion-rate functions. The ideas are illustrated on the example of nonparametric regression in Gaussian noise.\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Information-Theoretic Characterization of Achievable Predictor Performance': {\n",
      "  'relations': {\n",
      "    'is_about': 'Achievable Predictor Performance',\n",
      "    'uses': 'Conditional Distortion-Rate Functions',\n",
      "    'illustrated_by': 'Example of Nonparametric Regression in Gaussian Noise'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'context': 'Statistics and Information Theory',\n",
      "    'description': 'Theoretical Framework for Analyzing Predictor Performance'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Achievable Predictor Performance': {\n",
      "  'relations': {\n",
      "    'characterized_by': 'Information-Theoretic Characterization of Achievable Predictor Performance',\n",
      "    'dependent_on': 'X-values'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Measure of Predictor Accuracy'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Conditional Distortion-Rate Functions': {\n",
      "  'relations': {\n",
      "    'used_in': 'Information-Theoretic Characterization of Achievable Predictor Performance'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Mathematical Concept in Information Theory'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Example of Nonparametric Regression in Gaussian Noise': {\n",
      "  'relations': {\n",
      "    'illustrates': 'Information-Theoretic Characterization of Achievable Predictor Performance'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Specific Case Study in Regression Analysis'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Regression Analysis': {\n",
      "  'relations': {\n",
      "    'includes': 'Nonparametric Regression in Gaussian Noise'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Statistical Technique for Modeling Relationships'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Nonparametric Regression in Gaussian Noise': {\n",
      "  'relations': {\n",
      "    'is_a': 'Regression Analysis',\n",
      "    'is_illustrated_by': 'Example of Nonparametric Regression in Gaussian Noise'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Specific Type of Regression Analysis'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [ 71718090  97085922    761466  41423579 136245013 431253762 130903993\n",
      "    128961  47429823 579010519 646115823  74243328 187731381  67312031\n",
      " 116293349  20727983] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "In the context of statistics and information theory, a theoretical framework for analyzing predictor performance has been developed. This framework is characterized by the information-theoretic characterization of achievable predictor performance, which uses conditional distortion-rate functions. This concept is illustrated by an example of nonparametric regression in Gaussian noise.\n",
      "\n",
      "The achievable predictor performance is a measure of predictor accuracy, dependent on X-values. It is characterized by the information-theoretic characterization, which provides a theoretical foundation for understanding predictor performance. The conditional distortion-rate functions, a mathematical concept in information theory, play a crucial role in this characterization.\n",
      "\n",
      "The example of nonparametric regression in Gaussian noise serves as a specific case study in regression analysis, which is a statistical technique for modeling relationships. Nonparametric regression in Gaussian noise is a type of regression analysis, and this example illustrates the application of the information-theoretic characterization in this context.\n",
      "\n",
      "\n",
      "1\n",
      "1751\n",
      "In a sensor network, in practice, the communication among sensors is subject to:(1) errors or failures at random times; (3) costs; and(2) constraints since sensors and networks operate under scarce resources, such as power, data rate, or communication. The signal-to-noise ratio (SNR) is usually a main factor in determining the probability of error (or of communication failure) in a link. These probabilities are then a proxy for the SNR under which the links operate. The paper studies the problem of designing the topology, i.e., assigning the probabilities of reliable communication among sensors (or of link failures) to maximize the rate\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Sensor Network': {\n",
      "  'relations': {\n",
      "    'features_communication_errors': 'Random Errors or Failures',\n",
      "    'operates_under': 'Scarce Resources',\n",
      "    'communication_influenced_by': 'Signal-to-Noise Ratio (SNR)'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'characteristics': 'Prone to Errors or Failures, Costly, Constrained'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Random Errors or Failures': {\n",
      "  'relations': {\n",
      "    'occurs_in': 'Sensor Network',\n",
      "    'affects': 'Communication among Sensors'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'nature': 'Unpredictable, Random'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Scarce Resources': {\n",
      "  'relations': {\n",
      "    'limits': 'Sensor Network',\n",
      "    'types': ['Power', 'Data Rate', 'Communication']\n",
      "  },\n",
      "  'attributes': {\n",
      "    'nature': 'Limited, Constrained'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Signal-to-Noise Ratio (SNR)': {\n",
      "  'relations': {\n",
      "    'influences': 'Probability of Error or Communication Failure',\n",
      "    'determines': 'Link Quality'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Main Factor in Determining Probability of Error'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Probability of Error or Communication Failure': {\n",
      "  'relations': {\n",
      "    'determined_by': 'Signal-to-Noise Ratio (SNR)',\n",
      "    'proxy_for': 'Link Quality'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Measure of Link Reliability'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Link Quality': {\n",
      "  'relations': {\n",
      "    'proxy': 'Probability of Error or Communication Failure',\n",
      "    'influenced_by': 'Signal-to-Noise Ratio (SNR)'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Measure of Communication Reliability'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Topology Design Problem': {\n",
      "  'relations': {\n",
      "    'goal': 'Maximize Rate',\n",
      "    'involves': 'Assigning Probabilities of Reliable Communication'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Optimization Problem in Sensor Networks'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [  6133174  46317714  91521943  98785343  80304369   7829423  32799767\n",
      "  87159852  65066654  69172837  12520895  74243328  25367037  75666424\n",
      "  88401764 248393711] >\n",
      "</segment 1>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In a sensor network, communication errors or failures can occur randomly and unpredictably, affecting the communication among sensors. These errors or failures are a characteristic of the sensor network, which is prone to errors or failures, costly, and constrained. The sensor network operates under scarce resources, including power, data rate, and communication, which limits its performance.\n",
      "\n",
      "The communication in the sensor network is influenced by the signal-to-noise ratio (SNR), which is a main factor in determining the probability of error or communication failure. The SNR determines the link quality, which is a measure of communication reliability. A higher SNR results in a lower probability of error or communication failure, thereby improving the link quality.\n",
      "\n",
      "In the context of sensor networks, topology design is a critical problem that involves assigning probabilities of reliable communication. The goal of topology design is to maximize the rate of communication while ensuring reliable communication among sensors. This optimization problem is complex and requires careful consideration of the sensor network's characteristics, including its propensity for errors or failures, scarce resources, and communication constraints.\n",
      "\n",
      "\n",
      "of convergence of average consensus, when the link communication costs are taken into account, and there is an overall communication budget constraint. To consider this problem, we address a number of preliminary issues: (1) model the network as a random topology; (2) establish necessary and sufficient conditions for mean square sense (mss) and almost sure (a.s.) convergence of average consensus when network links fail; and, in particular, (3) show that a necessary and sufficient condition for both mss and a.s. convergence is for the algebraic connectivity of the mean graph describing the network topology to be strictly positive. With these\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Average Consensus Convergence Problem': {\n",
      "  'relations': {\n",
      "    'involves': 'Network Topology',\n",
      "    'has_constraints': 'Communication Budget Constraint'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Convergence of average consensus considering link communication costs',\n",
      "    'context': 'Distributed systems, Network topology'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Network Topology': {\n",
      "  'relations': {\n",
      "    'modeled_as': 'Random Topology',\n",
      "    'has_links': 'Network Links'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Structure of connections between nodes in a network',\n",
      "    'characteristic': 'Algebraic Connectivity'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Network Links': {\n",
      "  'relations': {\n",
      "    'fail': 'Link Failure',\n",
      "    'have_costs': 'Link Communication Costs'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Connections between nodes in a network',\n",
      "    'property': 'Reliability'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Link Communication Costs': {\n",
      "  'relations': {\n",
      "    'constrained_by': 'Communication Budget Constraint'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Costs associated with communication between nodes',\n",
      "    'unit': 'Unknown'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Communication Budget Constraint': {\n",
      "  'relations': {\n",
      "    'applies_to': 'Average Consensus Convergence Problem'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Limitation on total communication costs',\n",
      "    'value': 'Unknown'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Mean Square Sense Convergence': {\n",
      "  'relations': {\n",
      "    'required_for': 'Average Consensus Convergence Problem',\n",
      "    'has_necessary_condition': 'Algebraic Connectivity Condition'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Type of convergence in average consensus',\n",
      "    'abbreviation': 'MSS'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Almost Sure Convergence': {\n",
      "  'relations': {\n",
      "    'required_for': 'Average Consensus Convergence Problem',\n",
      "    'has_necessary_condition': 'Algebraic Connectivity Condition'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Type of convergence in average consensus',\n",
      "    'abbreviation': 'A.S.'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Algebraic Connectivity Condition': {\n",
      "  'relations': {\n",
      "    'necessary_for': ['Mean Square Sense Convergence', 'Almost Sure Convergence']\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Condition for convergence in average consensus',\n",
      "    'property': 'Strict Positivity'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [115315364  40757083    761466  37786043  33277103   6881145 164063332\n",
      " 224651096 153079691  76240938   3912752  74243328  31064039  45058861\n",
      "  95616906  66262755] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "In the context of distributed systems, the average consensus convergence problem is a critical issue that involves network topology. This problem is characterized by the convergence of average consensus considering link communication costs. In particular, it is essential to understand the structure of connections between nodes in a network, which is referred to as network topology.\n",
      "\n",
      "Network topology can be modeled as a random topology, and it consists of network links that connect nodes in the network. These links can fail, leading to link failure, and they are associated with link communication costs. The reliability of these links is a crucial property that affects the overall performance of the network.\n",
      "\n",
      "The link communication costs are constrained by the communication budget constraint, which imposes a limitation on the total communication costs. This constraint is a critical aspect of the average consensus convergence problem, as it directly affects the convergence of the system.\n",
      "\n",
      "To achieve convergence in the average consensus problem, two types of convergence are required: mean square sense (MSS) convergence and almost sure convergence. Both of these types of convergence have a necessary condition, known as the algebraic connectivity condition. This condition is characterized by strict positivity and is essential for ensuring convergence in the average consensus problem.\n",
      "\n",
      "\n",
      "results, we formulate topology design, subject to random link failures and to a communication cost constraint, as a constrained convex optimization problem to which we apply semidefinite programming techniques. We show by an extensive numerical study that the optimal design improves significantly the convergence speed of the consensus algorithm and can achieve the asymptotic performance of a non-random network at a fraction of the communication cost.\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Topology Design Problem': {\n",
      "  'relations': {\n",
      "    'formulated_as': 'Constrained Convex Optimization Problem',\n",
      "    'applies_techniques': 'Semidefinite Programming Techniques',\n",
      "    'subject_to': ['Random Link Failures', 'Communication Cost Constraint']\n",
      "  },\n",
      "  'attributes': {\n",
      "    'goal': 'Improve Convergence Speed of Consensus Algorithm',\n",
      "    'constraint': 'Communication Cost'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Constrained Convex Optimization Problem': {\n",
      "  'relations': {\n",
      "    'applied_to': 'Topology Design Problem',\n",
      "    'solved_by': 'Semidefinite Programming Techniques'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'type': 'Convex Optimization Problem',\n",
      "    'constraints': ['Random Link Failures', 'Communication Cost Constraint']\n",
      "  }\n",
      "},\n",
      "\n",
      "'Semidefinite Programming Techniques': {\n",
      "  'relations': {\n",
      "    'applied_to': 'Constrained Convex Optimization Problem',\n",
      "    'used_in': 'Topology Design Problem'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'type': 'Optimization Technique',\n",
      "    'application': 'Convex Optimization Problems'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Consensus Algorithm': {\n",
      "  'relations': {\n",
      "    'improved_by': 'Optimal Design',\n",
      "    'performance_metric': 'Convergence Speed'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'type': 'Distributed Algorithm',\n",
      "    'goal': 'Achieve Consensus'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Optimal Design': {\n",
      "  'relations': {\n",
      "    'improves': 'Convergence Speed of Consensus Algorithm',\n",
      "    'achieves': 'Asymptotic Performance of Non-Random Network'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'type': 'Topology Design',\n",
      "    'benefit': 'Improved Convergence Speed'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Non-Random Network': {\n",
      "  'relations': {\n",
      "    'asymptotic_performance_achieved_by': 'Optimal Design'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'type': 'Network Type',\n",
      "    'characteristic': 'No Random Link Failures'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [ 53641561  69645550  32523678  26799884 136245013   7829423  31366738\n",
      "  31699836 569583636  22783534   1409227  74243328  31064039 152505094\n",
      "  92123109 160888135] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "The Topology Design Problem is a complex issue that involves optimizing the design of a network to improve the convergence speed of consensus algorithms. This problem can be formulated as a Constrained Convex Optimization Problem, which can be solved using Semidefinite Programming Techniques. The goal of this optimization problem is to improve the convergence speed of consensus algorithms, subject to constraints such as random link failures and communication cost constraints.\n",
      "\n",
      "In this context, Semidefinite Programming Techniques are applied to solve the Constrained Convex Optimization Problem. These techniques are particularly useful for solving convex optimization problems, and their application to the Topology Design Problem enables the improvement of the convergence speed of consensus algorithms.\n",
      "\n",
      "The Consensus Algorithm, which is a distributed algorithm, is improved by the Optimal Design, which achieves the asymptotic performance of a non-random network. The Optimal Design is a topology design that improves the convergence speed of the consensus algorithm, thereby achieving the goal of improving the overall performance of the network.\n",
      "\n",
      "A non-random network is a type of network that is characterized by the absence of random link failures. The asymptotic performance of such a network is achieved by the Optimal Design, which ensures that the network operates at its optimal level.\n",
      "\n",
      "\n",
      "2\n",
      "1662\n",
      "The on-line shortest path problem is considered under various models of partial monitoring. Given a weighted directed acyclic graph whose edge weights can change in an arbitrary (adversarial) way, a decision maker has to choose in each round of a game a path between two distinguished vertices such that the loss of the chosen path (defined as the sum of the weights of its composing edges) be as small as possible. In a setting generalizing the multi-armed bandit problem, after choosing a path, the decision maker learns only the weights of those edges that belong to the chosen path. For\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<segment 1>\n",
      "\n",
      "\n",
      "'On-line Shortest Path Problem': {\n",
      "  'relations': {\n",
      "    'considered_under': 'Partial Monitoring Models',\n",
      "    'involves': 'Weighted Directed Acyclic Graph'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Optimizing path choice with minimal loss',\n",
      "    'context': 'Arbitrary edge weight changes'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Partial Monitoring Models': {\n",
      "  'relations': {\n",
      "    'generalize': 'Multi-armed Bandit Problem'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Learning from partial feedback'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Weighted Directed Acyclic Graph': {\n",
      "  'relations': {\n",
      "    'has': 'Edges with Changing Weights',\n",
      "    'features': 'Two Distinguished Vertices'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Graph with dynamic edge weights'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Edges with Changing Weights': {\n",
      "  'relations': {\n",
      "    'part_of': 'Weighted Directed Acyclic Graph'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Arbitrary weight changes'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Decision Maker': {\n",
      "  'relations': {\n",
      "    'plays': 'Game',\n",
      "    'learns_from': 'Partial Feedback'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Choosing paths to minimize loss'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Game': {\n",
      "  'relations': {\n",
      "    'features': 'Rounds',\n",
      "    'involves': 'Decision Maker'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Sequential path choice game'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Rounds': {\n",
      "  'relations': {\n",
      "    'part_of': 'Game'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Sequential iterations'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Partial Feedback': {\n",
      "  'relations': {\n",
      "    'received_by': 'Decision Maker'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Learning from chosen path edges'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [ 35045781  40835243  40672129  31149170  31750635   7829423  75803264\n",
      "  32682572  10677384 251167399  11836062   4170235 187731381   7369324\n",
      " 125287739   8604885] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "In the context of the On-line Shortest Path Problem, which involves optimizing path choice with minimal loss in a Weighted Directed Acyclic Graph with arbitrary edge weight changes, a Decision Maker plays a crucial role. The Decision Maker chooses paths to minimize loss, learning from partial feedback received from the Game. This Game is a sequential path choice game, consisting of Rounds, which are sequential iterations.\n",
      "\n",
      "The Weighted Directed Acyclic Graph, a key component of the On-line Shortest Path Problem, features two distinguished vertices and has edges with changing weights. These edges are characterized by arbitrary weight changes, which the Decision Maker must adapt to.\n",
      "\n",
      "The On-line Shortest Path Problem is considered under Partial Monitoring Models, which generalize the Multi-armed Bandit Problem. Partial Monitoring Models involve learning from partial feedback, where the Decision Maker receives feedback only on the chosen path edges.\n",
      "\n",
      "In this Game, the Decision Maker plays a crucial role in optimizing path choice, taking into account the dynamic edge weights and partial feedback. The ultimate goal is to minimize loss by choosing the optimal path in the Weighted Directed Acyclic Graph.\n",
      "\n",
      "\n",
      "this problem, an algorithm is given whose average cumulative loss in n rounds exceeds that of the best path, matched off-line to the entire sequence of the edge weights, by a quantity that is proportional to 1/\\sqrt{n} and depends only polynomially on the number of edges of the graph. The algorithm can be implemented with linear complexity in the number of rounds n and in the number of edges. An extension to the so-called label efficient setting is also given, in which the decision maker is informed about the weights of the edges corresponding to the chosen path at a\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Algorithm for Minimizing Cumulative Loss': {\n",
      "  'relations': {\n",
      "    'has_average_cumulative_loss': 'Quantity proportional to 1/\\sqrt{n}',\n",
      "    'exceeds': 'Best Path\\'s Cumulative Loss',\n",
      "    'implemented_with': 'Linear Complexity',\n",
      "    'extended_to': 'Label Efficient Setting'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'complexity': 'Linear in number of rounds n and number of edges',\n",
      "    'dependency': 'Polynomially dependent on number of edges'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Best Path\\'s Cumulative Loss': {\n",
      "  'relations': {\n",
      "    'matched_off-line_to': 'Entire Sequence of Edge Weights'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Optimal cumulative loss'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Entire Sequence of Edge Weights': {\n",
      "  'relations': {\n",
      "    'part_of': 'Graph'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Sequence of weights of all edges in the graph'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Graph': {\n",
      "  'relations': {\n",
      "    'has_edges': 'Edges'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Undirected graph with edge weights'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Edges': {\n",
      "  'relations': {\n",
      "    'part_of': 'Graph'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Collection of edges in the graph'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Label Efficient Setting': {\n",
      "  'relations': {\n",
      "    'extension_of': 'Algorithm for Minimizing Cumulative Loss'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Setting where decision maker is informed about chosen path\\'s edge weights'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [ 24568957  24867887   9024081  20022987  28072513 105651838 142171090\n",
      "  71658568  35928542  90094578  11836062  74243328 135302012  16738654\n",
      "  50053741 109808786] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "The algorithm for minimizing cumulative loss has a few key characteristics. Firstly, it has an average cumulative loss that is proportional to 1/\\sqrt{n}, where n is the number of rounds. Additionally, this algorithm exceeds the best path's cumulative loss, which is the optimal cumulative loss. The implementation of this algorithm has a linear complexity, making it efficient to execute.\n",
      "\n",
      "In the context of a graph, the best path's cumulative loss is matched offline to the entire sequence of edge weights. This sequence is a part of the graph, which is an undirected graph with edge weights. The graph, in turn, has edges, which are a collection of edges in the graph.\n",
      "\n",
      "Furthermore, the algorithm for minimizing cumulative loss has been extended to a label-efficient setting. In this setting, the decision-maker is informed about the chosen path's edge weights. This extension is a natural progression of the original algorithm.\n",
      "\n",
      "\n",
      "total of m << n time instances. Another extension is shown where the decision maker competes against a time-varying path, a generalization of the problem of tracking the best expert. A version of the multi-armed bandit setting for shortest path is also discussed where the decision maker learns only the total weight of the chosen path but not the weights of the individual edges on the path. Applications to routing in packet switched networks along with simulation results are also presented.\n",
      "<segment 1>\n",
      "\n",
      "\n",
      "'Multi-Armed Bandit Setting for Shortest Path': {\n",
      "  'relations': {\n",
      "    'is_extension_of': 'Multi-Armed Bandit Setting',\n",
      "    'is_generalization_of': 'Problem of Tracking the Best Expert'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'characteristics': 'Decision maker learns total weight of chosen path, not individual edge weights'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Multi-Armed Bandit Setting': {\n",
      "  'relations': {\n",
      "    'has_extension': 'Multi-Armed Bandit Setting for Shortest Path'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Decision maker competes against time-varying path'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Problem of Tracking the Best Expert': {\n",
      "  'relations': {\n",
      "    'is_generalized_by': 'Multi-Armed Bandit Setting for Shortest Path'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Decision maker competes against time-varying path'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Packet Switched Networks': {\n",
      "  'relations': {\n",
      "    'has_application': 'Multi-Armed Bandit Setting for Shortest Path'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Routing application'\n",
      "  }\n",
      "},\n",
      "\n",
      "'Simulation Results': {\n",
      "  'relations': {\n",
      "    'is_presented_along_with': 'Applications to Packet Switched Networks'\n",
      "  },\n",
      "  'attributes': {\n",
      "    'description': 'Results of simulations'\n",
      "  }\n",
      "}\n",
      "\n",
      "<source_sentence_min_hash: [112082167   9924331   9024081  52422527  14019373 313371142  56607342\n",
      "   3587349  47429823  90094578  11836062  74243328 129802786 170419165\n",
      "  49382248  72376750] >\n",
      "</segment 1>\n",
      "\n",
      "\n",
      "\n",
      "In the context of decision-making problems, the Multi-Armed Bandit Setting for Shortest Path is a specific extension of the general Multi-Armed Bandit Setting. This setting is characterized by the fact that the decision maker learns the total weight of the chosen path, rather than individual edge weights. This problem is a generalization of the Problem of Tracking the Best Expert, which also involves competing against time-varying paths.\n",
      "\n",
      "The Multi-Armed Bandit Setting, in turn, is a more general framework that has been extended to include the shortest path problem. In this setting, the decision maker competes against time-varying paths, and the goal is to make optimal decisions in the face of uncertainty.\n",
      "\n",
      "One of the key applications of the Multi-Armed Bandit Setting for Shortest Path is in Packet Switched Networks, where routing decisions need to be made in real-time. This problem is particularly relevant in network routing, where the goal is to find the shortest path to transmit packets efficiently.\n",
      "\n",
      "To demonstrate the effectiveness of this approach, Simulation Results have been presented alongside Applications to Packet Switched Networks. These results provide insights into the performance of the Multi-Armed Bandit Setting for Shortest Path in real-world scenarios, highlighting its potential to improve routing decisions in packet-switched networks.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_string_so_far_list = []\n",
    "all_kg_results = []\n",
    "all_reconstruction_results = []\n",
    "\n",
    "count = 0\n",
    "for input_text in concatenated_texts[0:3]:\n",
    "    print(count)\n",
    "    \n",
    "    count = count+1\n",
    "    print(len(input_text))\n",
    "    split_text = split_long_text(input_text, segment_length)\n",
    "    \n",
    "    #print(split_text[1])\n",
    "    input_split_texts = []\n",
    "    kg_for_input_split_texts = []\n",
    "    reconstruction_results_for_input_split_texts = []\n",
    "    \n",
    "    for each_split_text in split_text[0:len(split_text)]:\n",
    "        \n",
    "        print(each_split_text)\n",
    "        input_string_list, kg_results, reconstruction_results = KG_construction_and_reconstruction(each_split_text, model_name)\n",
    "        input_split_texts.append(input_string_list)\n",
    "        kg_for_input_split_texts.append(kg_results)\n",
    "        reconstruction_results_for_input_split_texts.append(reconstruction_results)\n",
    "        \n",
    "    input_string_so_far_list.append(flatten_list_of_lists(input_split_texts))\n",
    "    all_kg_results.append(flatten_list_of_lists(kg_for_input_split_texts))\n",
    "    all_reconstruction_results.append(flatten_list_of_lists(reconstruction_results_for_input_split_texts))\n",
    "    \n",
    "    #for i in range(0,len(split_text),1):\n",
    "     #   input_string_so_far_list, all_kg_results, all_reconstruction_results = KG_construction_and_reconstruction(split_text[i], model_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     if len(input_text)>1000:\n",
    "#         pass\n",
    "#     else:\n",
    "#         input_string_so_far_list, all_kg_results, all_reconstruction_results = KG_construction_and_reconstruction(input_text, model_name)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(input_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_split_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg_for_input_split_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction_results_for_input_split_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Input_Texts  \\\n",
      "0  The problem of statistical learning is to cons...   \n",
      "1  In a sensor network, in practice, the communic...   \n",
      "2  The on-line shortest path problem is considere...   \n",
      "\n",
      "                                       Output_Graphs  \\\n",
      "0  <style_analysis>This text exemplifies a formal...   \n",
      "1  <style_analysis>This text exemplifies a techni...   \n",
      "2  <style_analysis>This text is a prime example o...   \n",
      "\n",
      "                              Output_Reconstructions  \n",
      "0  \\n\\nIn the context of statistical learning pro...  \n",
      "1  \\n\\nIn a sensor network, communication errors ...  \n",
      "2  \\n\\nIn the context of the On-line Shortest Pat...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Input_Texts': input_string_so_far_list,\n",
    "    'Output_Graphs': all_kg_results,\n",
    "    'Output_Reconstructions': all_reconstruction_results, })\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "# print(\"500 word sample evalution:\", \"\\n\")\n",
    "# base_cap_500, original_cap_500, knowledgegraph_cap_500, reconstruction_cap_500,QA_df = evaluate_peformance(df, 2,\n",
    "#                                                                                                      \"q_a_kg.parquet\")\n",
    "\n",
    "# print(\"No context correct answer percentage:\", base_cap_500, \"\\n\")\n",
    "# print(\"Original context correct answer percentage:\", original_cap_500, \"\\n\")\n",
    "# print(\"Knowledgegraph context correct answer percentage:\", knowledgegraph_cap_500, \"\\n\")\n",
    "# print(\"Reconstruckted text context correct answer percentage:\", reconstruction_cap_500, \"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/test.csv\", encoding='utf-8', index=False)\n",
    "#QA_df.to_csv(\"data/questions_answer_save_200.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for input_text in concatenated_texts[2451:2500]:\n",
    "#     print(i)\n",
    "    \n",
    "#     i = i+1\n",
    "#     print(len(input_text))\n",
    "    \n",
    "#     #writing_style = get_style_genre(model_name, system_prompt, get_first_n_words(input_text, len(input_text))) #len(input_text) 1000\n",
    "#     writing_style = get_style_genre(get_first_n_words(input_text, len(input_text)), model_name, system_prompt) #len(input_text) 1000\n",
    "    \n",
    "#     sentences = [input_text]\n",
    "#     current_kg = []\n",
    "#     current_kg.append(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
    "#     segment_nr = 1\n",
    "#     reconstruction_so_far = \"\"\n",
    "#     input_string_so_far = \"\"\n",
    "#     for sentence in sentences:\n",
    "#         input_string_so_far += sentence\n",
    "#         if len(input_string_so_far) > stop_len:\n",
    "#             break\n",
    "#         current_kg_context = current_kg[-50:] if len(current_kg) > 50 else current_kg\n",
    "\n",
    "#             # Concatenate the elements into a single string\n",
    "#         current_kg_context = ' '.join(current_kg_context)\n",
    "\n",
    "#         text = scripts.prompts.KG_format_example_prompt(current_kg_context, sentence)\n",
    "        \n",
    "        \n",
    "#         try:\n",
    "#             for i in range(2):\n",
    "#                 knowledge_graph_segment = ask_LLM(model_name,\n",
    "#                                                     \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#                                                     text, API_KEY, temperature=0.5, top_p=0.95, max_tokens=1000,\n",
    "#                                                     frequency_penalty=1.1, presence_penalty=1.1)\n",
    "#                 if not (extract_kg_content(knowledge_graph_segment) == None):\n",
    "#                     break\n",
    "#             try:\n",
    "#                 current_kg.append(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "#                         knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#                 print(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "#                         knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#             except:\n",
    "#                 current_kg.append(\n",
    "#                         \"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "#                             create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#                 print(\"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "\n",
    "#             prompt = scripts.prompts.KG_reconstruction_prompt(reconstruction_so_far, current_kg)\n",
    "#             for i in range(2):\n",
    "#                 next_reconstruction = ask_LLM(model_name,\n",
    "#                                                 \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#                                                 prompt, API_KEY, temperature=0.5, top_p=0.95, max_tokens=4000,\n",
    "#                                                 frequency_penalty=1.1, presence_penalty=1.1)\n",
    "#                 if not (extract_reconstruction_content(next_reconstruction) == None):\n",
    "#                     break\n",
    "\n",
    "#             reconstruction_so_far += extract_reconstruction_content(next_reconstruction)\n",
    "#                 #print(reconstruction_so_far)\n",
    "\n",
    "#             print(extract_reconstruction_content(next_reconstruction))\n",
    "#             segment_nr += 1\n",
    "\n",
    "#             #all_kg_results.append(current_kg)\n",
    "#             #print(\"....................start....................................\")\n",
    "#             #print(current_kg.split(\"<source_sentence_min_hash:\"))\n",
    "\n",
    "#             #print(\"...............current kg........................\")\n",
    "#             #print(current_kg)\n",
    "\n",
    "#             #kg_String = ''.join(current_kg)\n",
    "        \n",
    "#         except:\n",
    "#             print(\"No Kg found\")\n",
    "            \n",
    "#         try:\n",
    "#             all_kg_results.append(current_kg)\n",
    "\n",
    "#                 #print(\".....................current kg end.........................\")\n",
    "#                 #all_reconstruction_results.append(reconstruction_so_far)\n",
    "#                 #print(reconstruction_so_far.split(\"<source_sentence_min_hash:\")[0])\n",
    "#                 #reconstruction_String = ''.join(reconstruction_so_far)\n",
    "#             all_reconstruction_results.append(reconstruction_so_far)\n",
    "#                 #print(\"....................end....................................\")\n",
    "\n",
    "#             input_string_so_far_list.append(input_string_so_far)\n",
    "        \n",
    "#         except:\n",
    "#             print(\"Pass because of no Kg found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# for input_text in concatenated_texts[101:200]:\n",
    "#     try:\n",
    "#         print(i)\n",
    "\n",
    "#         i = i+1\n",
    "#         print(len(input_text))\n",
    "#         writing_style = get_style_genre(get_first_n_words(input_text, len(input_text))) #len(input_text) 1000\n",
    "#         sentences = [input_text]\n",
    "#         current_kg = []\n",
    "#         current_kg.append(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
    "#         segment_nr = 1\n",
    "#         reconstruction_so_far = \"\"\n",
    "#         input_string_so_far = \"\"\n",
    "#         for sentence in sentences:\n",
    "#             input_string_so_far += sentence\n",
    "#             if len(input_string_so_far) > stop_len:\n",
    "#                 break\n",
    "#             current_kg_context = current_kg[-50:] if len(current_kg) > 50 else current_kg\n",
    "\n",
    "#                 # Concatenate the elements into a single string\n",
    "#             current_kg_context = ' '.join(current_kg_context)\n",
    "\n",
    "#             text = scripts.prompts.KG_format_example_prompt(current_kg_context, sentence)\n",
    "\n",
    "#             for i in range(2):\n",
    "#                 knowledge_graph_segment = ask_LLM(model_name,\n",
    "#                                                     \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#                                                     text, API_KEY, temperature=0.1, top_p=0.95, max_tokens=1000,\n",
    "#                                                     frequency_penalty=1.1, presence_penalty=1.1)\n",
    "#                 if not (extract_kg_content(knowledge_graph_segment) == None):\n",
    "#                     break\n",
    "#             try:\n",
    "#                 current_kg.append(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "#                         knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#                 print(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "#                         knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#             except:\n",
    "#                 current_kg.append(\n",
    "#                         \"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "#                             create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#                 print(\"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "\n",
    "#             prompt = scripts.prompts.KG_reconstruction_prompt(reconstruction_so_far, current_kg)\n",
    "#             for i in range(2):\n",
    "#                 next_reconstruction = ask_LLM(model_name,\n",
    "#                                                 \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#                                                 prompt, API_KEY, temperature=0.5, top_p=0.95, max_tokens=4000,\n",
    "#                                                 frequency_penalty=1.1, presence_penalty=1.1)\n",
    "#                 if not (extract_reconstruction_content(next_reconstruction) == None):\n",
    "#                     break\n",
    "\n",
    "#             reconstruction_so_far += extract_reconstruction_content(next_reconstruction)\n",
    "#                 #print(reconstruction_so_far)\n",
    "\n",
    "#             print(extract_reconstruction_content(next_reconstruction))\n",
    "#             segment_nr += 1\n",
    "\n",
    "#             #all_kg_results.append(current_kg)\n",
    "#             #print(\"....................start....................................\")\n",
    "#             #print(current_kg.split(\"<source_sentence_min_hash:\"))\n",
    "\n",
    "#             #print(\"...............current kg........................\")\n",
    "#             #print(current_kg)\n",
    "\n",
    "#             #kg_String = ''.join(current_kg)\n",
    "#         all_kg_results.append(current_kg)\n",
    "\n",
    "#             #print(\".....................current kg end.........................\")\n",
    "#             #all_reconstruction_results.append(reconstruction_so_far)\n",
    "#             #print(reconstruction_so_far.split(\"<source_sentence_min_hash:\")[0])\n",
    "#             #reconstruction_String = ''.join(reconstruction_so_far)\n",
    "#         all_reconstruction_results.append(reconstruction_so_far)\n",
    "#             #print(\"....................end....................................\")\n",
    "\n",
    "#         input_string_so_far_list.append(input_string_so_far)\n",
    "\n",
    "#     except:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for input_text in concatenated_texts[0:1000]:\n",
    "#     print(i)\n",
    "    \n",
    "#     i = i+1\n",
    "#     print(len(input_text))\n",
    "#     #print(input_text)\n",
    "#     try:\n",
    "\n",
    "#         writing_style = get_style_genre(get_first_n_words(input_text, len(input_text))) #len(input_text) 1000\n",
    "\n",
    "#         # sentences= text_to_sentences(input_text)\n",
    "#         # sentences =sentences_to_large_strings(sentences)\n",
    "#         sentences = [input_text]\n",
    "#         # print(sentences)\n",
    "#         # continue\n",
    "#         current_kg = []\n",
    "#         current_kg.append(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
    "#         #print(\"<style_analysis>\" + writing_style + \"</style_analysis>\")\n",
    "#         segment_nr = 1\n",
    "#         reconstruction_so_far = \"\"\n",
    "#         input_string_so_far = \"\"\n",
    "#         for sentence in sentences:\n",
    "#             input_string_so_far += sentence\n",
    "#             if len(input_string_so_far) > stop_len:\n",
    "#                 break\n",
    "#             #print(\"INPUT:\", sentence)\n",
    "#             # print(\"-----\")\n",
    "#             # '''\n",
    "#             # prompt=\"\"\"INPUT_TEXT:\n",
    "#             # \"\"\"+sentence+\"\"\"\n",
    "#             # INSTRUCTION:\n",
    "#             # Paraphrase the given input text so that every statement is rephrased into sentences that contain only three to ten words each.\n",
    "#             #   Use a simple structure and make sure to retain all information, names, numbers, and dates from the original text, without losing\n",
    "#             #     any information. The output text should consist exclusively of factual, neutrally phrased sentences that are three to ten words\n",
    "#             #       long. All information must be preserved, but without any artistic nuances. Direct speech in the source text should not be\n",
    "#             #         replicated as such, but it should be laid out in short sentences who said or did what in which order, ensuring a neutral,\n",
    "#             #           information-rich text.\"\"\"\n",
    "    \n",
    "#             # reply = ask_LLM ('NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO',\n",
    "#             #   \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#             #     input_text , API_KEY ,temperature=0.5,top_p=0.95,max_tokens=1000, frequency_penalty=1.1,presence_penalty=1.1)\n",
    "#             # '''\n",
    "\n",
    "#             # Determine the slice of the last 50 elements (if the list has more than 50 elements)\n",
    "#             current_kg_context = current_kg[-50:] if len(current_kg) > 50 else current_kg\n",
    "\n",
    "#             # Concatenate the elements into a single string\n",
    "#             current_kg_context = ' '.join(current_kg_context)\n",
    "\n",
    "#             #print(\".....................KG_format_example_prompt start.......................\")\n",
    "#             text = scripts.prompts.KG_format_example_prompt(current_kg_context, sentence)\n",
    "#             #print(text)\n",
    "#             #print(\".....................KG_format_example_prompt end.......................\")\n",
    "\n",
    "#             for i in range(2):\n",
    "#                 knowledge_graph_segment = ask_LLM(model_name,\n",
    "#                                                 \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#                                                 text, API_KEY, temperature=0.1, top_p=0.95, max_tokens=1000,\n",
    "#                                                 frequency_penalty=1.1, presence_penalty=1.1)\n",
    "#                 if not (extract_kg_content(knowledge_graph_segment) == None):\n",
    "#                     break\n",
    "#             try:\n",
    "#                 current_kg.append(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "#                     knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "#                     create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#                 print(\"<segment \" + str(segment_nr) + \">\\n\" + extract_kg_content(\n",
    "#                     knowledge_graph_segment) + \"<source_sentence_min_hash: \" + str(\n",
    "#                     create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#             except:\n",
    "#                 current_kg.append(\n",
    "#                     \"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "#                         create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "#                 print(\"<segment \" + str(segment_nr) + \">\\n\" + knowledge_graph_segment + \"<source_sentence_min_hash: \" + str(\n",
    "#                     create_minhash_vector(sentence)) + \" >\\n\" + \"</segment \" + str(segment_nr) + \">\\n\")\n",
    "\n",
    "#             prompt = scripts.prompts.KG_reconstruction_prompt(reconstruction_so_far, current_kg)\n",
    "#             for i in range(2):\n",
    "#                 next_reconstruction = ask_LLM(model_name,\n",
    "#                                             \"You are a very smart very intelligence assistant who is very helpful.\",\n",
    "#                                             prompt, API_KEY, temperature=0.5, top_p=0.95, max_tokens=4000,\n",
    "#                                             frequency_penalty=1.1, presence_penalty=1.1)\n",
    "#                 if not (extract_reconstruction_content(next_reconstruction) == None):\n",
    "#                     break\n",
    "\n",
    "#             reconstruction_so_far += extract_reconstruction_content(next_reconstruction)\n",
    "#             #print(reconstruction_so_far)\n",
    "            \n",
    "#             print(extract_reconstruction_content(next_reconstruction))\n",
    "#             segment_nr += 1\n",
    "            \n",
    "#         #all_kg_results.append(current_kg)\n",
    "#         #print(\"....................start....................................\")\n",
    "#         #print(current_kg.split(\"<source_sentence_min_hash:\"))\n",
    "        \n",
    "#         #print(\"...............current kg........................\")\n",
    "#         #print(current_kg)\n",
    "        \n",
    "#         #kg_String = ''.join(current_kg)\n",
    "#         all_kg_results.append(current_kg)\n",
    "        \n",
    "#         #print(\".....................current kg end.........................\")\n",
    "#         #all_reconstruction_results.append(reconstruction_so_far)\n",
    "#         #print(reconstruction_so_far.split(\"<source_sentence_min_hash:\")[0])\n",
    "#         #reconstruction_String = ''.join(reconstruction_so_far)\n",
    "#         all_reconstruction_results.append(reconstruction_so_far)\n",
    "#         #print(\"....................end....................................\")\n",
    "        \n",
    "#         input_string_so_far_list.append(input_string_so_far)\n",
    "        \n",
    "        \n",
    "# #         print(\"\\n\")\n",
    "# #         print(\"......all_kg_results............\")\n",
    "# #         print(\"\\n\")\n",
    "# #         print(all_kg_results)\n",
    "        \n",
    "# #         print(\"\\n\")\n",
    "# #         print(\"......reconstruction text............\")\n",
    "# #         print(\"\\n\")\n",
    "# #         print(all_reconstruction_results)\n",
    "#     except:\n",
    "#         print(i)\n",
    "#         pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'Input_Texts': input_string_so_far_list,\n",
    "#     'Output_Graphs': all_kg_results,\n",
    "#     'Output_Reconstructions': all_reconstruction_results, })\n",
    "\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# # print(\"500 word sample evalution:\", \"\\n\")\n",
    "# # base_cap_500, original_cap_500, knowledgegraph_cap_500, reconstruction_cap_500,QA_df = evaluate_peformance(df, 2,\n",
    "# #                                                                                                      \"q_a_kg.parquet\")\n",
    "\n",
    "# # print(\"No context correct answer percentage:\", base_cap_500, \"\\n\")\n",
    "# # print(\"Original context correct answer percentage:\", original_cap_500, \"\\n\")\n",
    "# # print(\"Knowledgegraph context correct answer percentage:\", knowledgegraph_cap_500, \"\\n\")\n",
    "# # print(\"Reconstruckted text context correct answer percentage:\", reconstruction_cap_500, \"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/df_save_2500.csv\", encoding='utf-8', index=False)\n",
    "# #QA_df.to_csv(\"data/questions_answer_save_200.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 paper for cot: \n",
    "\n",
    "# No context correct answer percentage: 44.19784400760939 \n",
    "\n",
    "# Original context correct answer percentage: 84.14647730437204 \n",
    "\n",
    "# Knowledgegraph context correct answer percentage: 77.47158824081902 \n",
    "\n",
    "# Reconstruckted text context correct answer percentage: 77.27733804656881 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
